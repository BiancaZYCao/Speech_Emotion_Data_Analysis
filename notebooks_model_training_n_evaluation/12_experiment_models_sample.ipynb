{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8dba9c2-50a6-4935-85c4-36c696e704fb",
   "metadata": {
    "id": "e8dba9c2-50a6-4935-85c4-36c696e704fb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "VERSION = 4\n",
    "RANDOM_SEED = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KR08Ma0kO74a",
   "metadata": {
    "id": "KR08Ma0kO74a"
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e31f3f-dc53-4213-8f43-3483d34dfec3",
   "metadata": {
    "id": "97e31f3f-dc53-4213-8f43-3483d34dfec3"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "DR2pv3_iEvUw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DR2pv3_iEvUw",
    "outputId": "fa93808b-eb0c-4608-ef4e-ea6662277e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      " code  'Colab Notebooks'   data_extracted_features   dataset   dataset_split   models\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/gdrive/My Drive/')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659733a7-b892-482e-b64f-459f44cc7a78",
   "metadata": {
    "id": "659733a7-b892-482e-b64f-459f44cc7a78"
   },
   "source": [
    "### Load Data - downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e49c50-5175-47ef-b9fa-8880cff6e84e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21e49c50-5175-47ef-b9fa-8880cff6e84e",
    "outputId": "24edc1f3-5671-4e29-a3e0-677f54be73f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of test  set:  (680, 1546)\n",
      "shape of train set:  (24885, 1546)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment_value\n",
       "-1    7999\n",
       " 0    8560\n",
       " 1    8326\n",
       "Name: file_path, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_joint_train_org   = pd.read_csv(f'./data_extracted_features/cache_all_features_train_V{VERSION}.csv')\n",
    "# df_joint_train_org   = df_joint_train_org.drop(columns=['GNE_max_gne','GNE_mean_gne','GNE_stddev_gne','GNE_sum_gne'])\n",
    "\n",
    "# df_joint_test_org = pd.read_csv(f'./data_extracted_features/cache_all_features_test_V{VERSION}.csv').drop(\n",
    "#     columns=['GNE_max_gne','GNE_mean_gne','GNE_stddev_gne','GNE_sum_gne'])\n",
    "\n",
    "# print(\"shape of train set: \", df_joint_train_org.shape)\n",
    "# print(\"shape of test  set: \", df_joint_test_org.shape)\n",
    "\n",
    "\n",
    "# df_joint_train  = pd.read_csv(f'./data_extracted_features/cache_train_V4_resampled_2500.csv')\n",
    "df_joint_test = pd.read_csv(f'./features/cache_test_V4_resampled_250.csv')\n",
    "\n",
    "# print(\"shape of train set: \", df_joint_train.shape)\n",
    "print(\"shape of test  set: \", df_joint_test.shape)\n",
    "\n",
    "df_joint_train_aug  = pd.read_csv(f'./features/cache_train_V4_augmented.csv')\n",
    "feature_column_names = [i for i in df_joint_train_aug.columns \\\n",
    "                        if i not in ['file_path','renamed_file_path','split','sentiment_value','emotional_category']]\n",
    "\n",
    "print(\"shape of train set: \", df_joint_train_aug.shape)\n",
    "df_joint_train_aug.groupby('sentiment_value')['file_path'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7410936-ebd7-4086-8cef-258f277df6a5",
   "metadata": {
    "id": "e7410936-ebd7-4086-8cef-258f277df6a5"
   },
   "source": [
    "### best guess feature combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d60449b-65d7-4052-96bf-1b4ed2012440",
   "metadata": {
    "id": "1d60449b-65d7-4052-96bf-1b4ed2012440"
   },
   "outputs": [],
   "source": [
    "# generate selected features\n",
    "def generate_selected_features_by_type(feature_column_names,input,stats,number=1):\n",
    "    selected_result = []\n",
    "    for name in feature_column_names:\n",
    "        if input+\"_\"+stats in name:\n",
    "            selected_result.append(name)\n",
    "    if number < len(selected_result):\n",
    "        selected_result = selected_result[:number]\n",
    "    return selected_result\n",
    "\n",
    "# example to take mfcc 20 mean & std; mel32; zcr all 5 stats features\n",
    "feature_MFCC20_mean  = generate_selected_features_by_type(feature_column_names,\"mfcc\",\"mean\",20)\n",
    "feature_MFCC20_std   = generate_selected_features_by_type(feature_column_names,\"mfcc\",\"std\",20)\n",
    "feature_mel32_median = generate_selected_features_by_type(feature_column_names,\"mel32\",\"median\",32)\n",
    "feature_mel32_std    = generate_selected_features_by_type(feature_column_names,\"mel32\",\"std\",32)\n",
    "feature_zcr_stats    = generate_selected_features_by_type(feature_column_names,\"zcr\",\"\",5)\n",
    "feature_rms_stats    = generate_selected_features_by_type(feature_column_names,\"rms\",\"\",5)\n",
    "selected_spect = ['Spectrum_band_energy_difference','Spectrum_band_density_difference','Spectrum_center_of_gravity_spectrum','Spectrum_skewness_spectrum','Spectrum_kurtosis_spectrum', 'Spectrum_stddev_spectrum','Spectrum_band_density', 'Spectrum_band_energy']\n",
    "selected_formant = ['Formant_f1_mean','Formant_f1_median','Formant_f3_mean','Formant_fitch_vtl','Formant_mff','Formant_formant_dispersion']\n",
    "selected_pitch = ['Pitch_pitch_slope_without_octave_jumps', 'Pitch_q3_pitch','Pitch_stddev_pitch', 'Pitch_mean_absolute_pitch_slope','Pitch_mean_pitch', 'Pitch_max_pitch', 'Pitch_q1_pitch', 'Pitch_min_pitch']\n",
    "selected_intensity = ['Intensity_max_intensity', 'Intensity_q3_intensity','Intensity_median_intensity', 'Intensity_mean_intensity', 'Intensity_stddev_intensity','Intensity_relative_max_intensity_time']\n",
    "selected_HNR = ['HNR_stddev_hnr', 'HNR_mean_hnr','HNR_relative_min_hnr_time','HNR_max_hnr']\n",
    "selected_prosody = selected_intensity + selected_pitch # + ['Local Jitter','Local Shimmer']\n",
    "selected_feature_names = feature_MFCC20_mean + feature_MFCC20_std + feature_mel32_median + feature_mel32_std + \\\n",
    "                         feature_rms_stats + selected_intensity + selected_pitch + selected_spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35ff200-a507-4585-8895-cd6078d86277",
   "metadata": {
    "id": "b35ff200-a507-4585-8895-cd6078d86277"
   },
   "outputs": [],
   "source": [
    "# default use augmented training set and balanced test set\n",
    "X_train = df_joint_train_aug[selected_feature_names]\n",
    "y_train_s = df_joint_train_aug['sentiment_value']\n",
    "y_train_e = df_joint_train_aug['emotional_category']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_e_num = label_encoder.fit_transform(y_train_e)\n",
    "\n",
    "X_test = df_joint_test[selected_feature_names]\n",
    "y_test_s = df_joint_test['sentiment_value']\n",
    "y_test_e = df_joint_test['emotional_category']\n",
    "\n",
    "y_test_e_num = label_encoder.fit_transform(y_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca14499a-4cd4-4074-9b06-abcc64528146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_intensity), len(selected_pitch), len(selected_spect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1663e5-5686-40cc-9141-45e27b2d20d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a1663e5-5686-40cc-9141-45e27b2d20d3",
    "outputId": "8bcf07cc-310d-42b2-d65d-7f78b8e1e118"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24885, 131), (680, 131))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c5de8-86fb-4ded-9158-71f1f2c2958a",
   "metadata": {
    "id": "ad8c5de8-86fb-4ded-9158-71f1f2c2958a"
   },
   "source": [
    "## Models - conventional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484c6370-fd24-4584-9484-c61b8e2fc061",
   "metadata": {
    "id": "484c6370-fd24-4584-9484-c61b8e2fc061"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier,HistGradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Common adjustable parameters\n",
    "common_params = {\n",
    "    'RandomForest': {'n_estimators': 100, 'criterion':'gini', 'max_depth': None,\n",
    "                     'min_samples_split':100, 'bootstrap':True, 'n_jobs':3, 'random_state': RANDOM_SEED},\n",
    "    'SVM': {'kernel': 'rbf', 'C': 1.0, 'probability': True},\n",
    "    'KNN': {'n_neighbors': 5},\n",
    "    'GradientBoosting': {'loss': 'log_loss', 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0,\n",
    "                         'criterion': 'friedman_mse', 'min_samples_split': 2, 'max_depth': 3},\n",
    "    'GradientBoostingFast': {'loss': 'log_loss', 'learning_rate': 0.1, 'max_iter': 100},\n",
    "    'AdaBoost': {'n_estimators': 50, 'learning_rate': 1.0},\n",
    "    'LightGBM': {'boosting_type': 'gbdt', 'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0,\n",
    "                 'min_child_samples': 20, 'max_depth': -1}\n",
    "}\n",
    "\n",
    "# Models with common adjustable parameters\n",
    "dtree   = DecisionTreeClassifier()\n",
    "rforest = RandomForestClassifier(**common_params['RandomForest'])\n",
    "svm     = SVC(**common_params['SVM'])\n",
    "knn     = KNeighborsClassifier(**common_params['KNN'])\n",
    "gboost  = GradientBoostingClassifier(**common_params['GradientBoosting'])\n",
    "gb_fast = HistGradientBoostingClassifier(**common_params['GradientBoostingFast'])\n",
    "adaBoost= AdaBoostClassifier(**common_params['AdaBoost'])\n",
    "lightgbm=LGBMClassifier(**common_params['LightGBM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sm5XouA3GcU7",
   "metadata": {
    "id": "sm5XouA3GcU7"
   },
   "source": [
    "### experiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580e3cad",
   "metadata": {
    "id": "580e3cad"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def exp_clf_with_feature_selected(clf_model, X_train, X_test, y_train, y_test,verbose=True):\n",
    "    start = time.time()\n",
    "\n",
    "    clf_model.fit(X_train, y_train)\n",
    "    predictions = clf_model.predict(X_test.values)\n",
    "\n",
    "    # Calculate metrics\n",
    "    report = classification_report(y_test, predictions, output_dict=True)\n",
    "    metrics = {\n",
    "        'accuracy': report['accuracy'],\n",
    "        'precision': report['macro avg']['precision'],\n",
    "        'recall': report['macro avg']['recall'],\n",
    "        'f1-score': report['macro avg']['f1-score']\n",
    "    }\n",
    "    for class_name in report.keys():\n",
    "        if class_name not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "            metrics[class_name+'_precision'] = report[class_name]['precision']\n",
    "            metrics[class_name+'_recall'] = report[class_name]['recall'],\n",
    "            metrics[class_name+'_f1-score'] = report[class_name]['f1-score']\n",
    "\n",
    "    feature_columns = list(X_train.columns)\n",
    "    num_classes = y_train.nunique()\n",
    "    class_names = list(y_train.unique())\n",
    "\n",
    "    model_filename = f\"./models/{clf_model.__class__.__name__}_model\"\n",
    "    model_filename += f\"_{num_classes}cls_{len(feature_columns)}feat_{round(report['accuracy']*100)}acc.pkl\"\n",
    "    with open(model_filename, 'wb') as file:\n",
    "        pickle.dump(clf_model, file)\n",
    "\n",
    "    results = {**metrics,\n",
    "        'num_classes': num_classes,\n",
    "        'class_names': class_names,\n",
    "        'model_filename': model_filename,\n",
    "        'feature_columns': feature_columns,\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Model Name: {clf_model.__class__.__name__};\\nTrain set shape {X_train.shape}, num of class {num_classes}\")\n",
    "        print(classification_report(y_test, predictions))\n",
    "        print(confusion_matrix(y_test, predictions))\n",
    "        probabilities = clf_model.predict_proba(X_test.values)\n",
    "        print('Probabilities distribution:\\n', pd.DataFrame(probabilities, columns=clf_model.classes_).describe())\n",
    "    print(f\"Model: {clf_model.__class__.__name__};Time taken: {round(time.time()-start, 3)} seconds.\\n\")\n",
    "\n",
    "    return results, clf_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc283451-e5be-41f4-9936-9cfc26c33c4b",
   "metadata": {
    "id": "dc283451-e5be-41f4-9936-9cfc26c33c4b"
   },
   "source": [
    "### Sentiment 3-class Classifier Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de039fa",
   "metadata": {
    "id": "4de039fa",
    "outputId": "c164d7de-45ce-4b10-8975-91d1aaa69e72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: RandomForestClassifier;\n",
      "Train set shape (24885, 131), num of class 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.77      0.73       248\n",
      "           0       0.68      0.86      0.76       183\n",
      "           1       0.88      0.62      0.73       249\n",
      "\n",
      "    accuracy                           0.74       680\n",
      "   macro avg       0.75      0.75      0.74       680\n",
      "weighted avg       0.76      0.74      0.74       680\n",
      "\n",
      "[[191  41  16]\n",
      " [ 20 158   5]\n",
      " [ 61  33 155]]\n",
      "Probabilities distribution:\n",
      "                -1           0           1\n",
      "count  680.000000  680.000000  680.000000\n",
      "mean     0.398042    0.281497    0.320461\n",
      "std      0.227307    0.264152    0.270539\n",
      "min      0.008433    0.000200    0.004270\n",
      "25%      0.258860    0.025624    0.111430\n",
      "50%      0.369035    0.216568    0.230583\n",
      "75%      0.543687    0.476297    0.424664\n",
      "max      0.952376    0.982654    0.990326\n",
      "Model: RandomForestClassifier;Time taken: 5.237 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change model as the first parameter in the function\n",
    "result, m_trained = exp_clf_with_feature_selected(rforest, X_train, X_test, y_train_s, y_test_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b833185",
   "metadata": {
    "id": "3b833185"
   },
   "source": [
    "### How to save experiment metrics result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40156aa6",
   "metadata": {
    "id": "40156aa6"
   },
   "outputs": [],
   "source": [
    "exp_results = []\n",
    "for clf_model in [rforest, knn, gb_fast,adaBoost]:\n",
    "    result, m_trained = exp_clf_with_feature_selected(clf_model, X_train, X_test, y_train_s, y_test_s,verbose=False)\n",
    "    exp_results.append(result)\n",
    "pd.DataFrame(exp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc7ece",
   "metadata": {
    "id": "77cc7ece"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(exp_results).to_excel(\"exp_result.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb541dfd",
   "metadata": {
    "id": "fb541dfd"
   },
   "source": [
    "### Emotion 8-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e118a0a7",
   "metadata": {
    "id": "e118a0a7",
    "outputId": "e3673e05-e280-4f76-84a6-102228db8922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: RandomForestClassifier;\n",
      "Train set shape (24885, 84), num of class 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger       0.74      0.65      0.69        62\n",
      "    Calmness       0.39      1.00      0.56        16\n",
      "     Disgust       0.72      0.21      0.33        62\n",
      "        Fear       0.94      0.26      0.41        62\n",
      "   Happiness       0.69      0.67      0.68       187\n",
      "  Neutrality       0.59      0.88      0.71       167\n",
      "     Sadness       0.56      0.52      0.54        62\n",
      "    Surprise       0.87      0.85      0.86        62\n",
      "\n",
      "    accuracy                           0.65       680\n",
      "   macro avg       0.69      0.63      0.60       680\n",
      "weighted avg       0.69      0.65      0.63       680\n",
      "\n",
      "[[ 40   0   0   0  18   1   1   2]\n",
      " [  0  16   0   0   0   0   0   0]\n",
      " [  0   3  13   1  14  25   5   1]\n",
      " [  1   0   1  16  14  18   9   3]\n",
      " [ 13   7   4   0 125  35   2   1]\n",
      " [  0   8   0   0   4 147   8   0]\n",
      " [  0   5   0   0   2  22  32   1]\n",
      " [  0   2   0   0   5   2   0  53]]\n",
      "Probabilities distribution:\n",
      "             Anger    Calmness     Disgust        Fear   Happiness  Neutrality  \\\n",
      "count  680.000000  680.000000  680.000000  680.000000  680.000000  680.000000   \n",
      "mean     0.096420    0.033469    0.092105    0.096714    0.234033    0.259244   \n",
      "std      0.151980    0.112901    0.087261    0.111521    0.206461    0.264417   \n",
      "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000195   \n",
      "25%      0.010949    0.000102    0.038155    0.038073    0.082225    0.023016   \n",
      "50%      0.028116    0.001210    0.083293    0.076289    0.168534    0.170945   \n",
      "75%      0.105712    0.004841    0.115638    0.118327    0.326164    0.454171   \n",
      "max      0.901417    0.755536    0.785445    0.886855    0.975262    0.997965   \n",
      "\n",
      "          Sadness    Surprise  \n",
      "count  680.000000  680.000000  \n",
      "mean     0.099745    0.088269  \n",
      "std      0.136833    0.184769  \n",
      "min      0.000236    0.000000  \n",
      "25%      0.014152    0.004628  \n",
      "50%      0.053731    0.017077  \n",
      "75%      0.115156    0.071423  \n",
      "max      0.705089    0.949723  \n",
      "Model: RandomForestClassifier;Time taken: 4.42 seconds.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.65,\n",
       "  'precision': 0.6874315613239665,\n",
       "  'recall': 0.6290699608201227,\n",
       "  'f1-score': 0.5954085578190418,\n",
       "  'Anger_precision': 0.7407407407407407,\n",
       "  'Anger_recall': (0.6451612903225806,),\n",
       "  'Anger_f1-score': 0.689655172413793,\n",
       "  'Calmness_precision': 0.3902439024390244,\n",
       "  'Calmness_recall': (1.0,),\n",
       "  'Calmness_f1-score': 0.5614035087719299,\n",
       "  'Disgust_precision': 0.7222222222222222,\n",
       "  'Disgust_recall': (0.20967741935483872,),\n",
       "  'Disgust_f1-score': 0.325,\n",
       "  'Fear_precision': 0.9411764705882353,\n",
       "  'Fear_recall': (0.25806451612903225,),\n",
       "  'Fear_f1-score': 0.4050632911392405,\n",
       "  'Happiness_precision': 0.6868131868131868,\n",
       "  'Happiness_recall': (0.6684491978609626,),\n",
       "  'Happiness_f1-score': 0.6775067750677507,\n",
       "  'Neutrality_precision': 0.588,\n",
       "  'Neutrality_recall': (0.8802395209580839,),\n",
       "  'Neutrality_f1-score': 0.7050359712230216,\n",
       "  'Sadness_precision': 0.5614035087719298,\n",
       "  'Sadness_recall': (0.5161290322580645,),\n",
       "  'Sadness_f1-score': 0.5378151260504201,\n",
       "  'Surprise_precision': 0.8688524590163934,\n",
       "  'Surprise_recall': (0.8548387096774194,),\n",
       "  'Surprise_f1-score': 0.8617886178861789,\n",
       "  'num_classes': 8,\n",
       "  'class_names': ['Disgust',\n",
       "   'Anger',\n",
       "   'Fear',\n",
       "   'Sadness',\n",
       "   'Happiness',\n",
       "   'Surprise',\n",
       "   'Neutrality',\n",
       "   'Calmness'],\n",
       "  'model_filename': './models/RandomForestClassifier_model_8cls_84feat_65acc.pkl',\n",
       "  'feature_columns': ['mfcc_mean_1',\n",
       "   'mfcc_mean_2',\n",
       "   'mfcc_mean_3',\n",
       "   'mfcc_mean_4',\n",
       "   'mfcc_mean_5',\n",
       "   'mfcc_mean_6',\n",
       "   'mfcc_mean_7',\n",
       "   'mfcc_mean_8',\n",
       "   'mfcc_mean_9',\n",
       "   'mfcc_mean_10',\n",
       "   'mfcc_mean_11',\n",
       "   'mfcc_mean_12',\n",
       "   'mfcc_mean_13',\n",
       "   'mfcc_mean_14',\n",
       "   'mfcc_mean_15',\n",
       "   'mfcc_mean_16',\n",
       "   'mfcc_mean_17',\n",
       "   'mfcc_mean_18',\n",
       "   'mfcc_mean_19',\n",
       "   'mfcc_mean_20',\n",
       "   'mfcc_std_1',\n",
       "   'mfcc_std_2',\n",
       "   'mfcc_std_3',\n",
       "   'mfcc_std_4',\n",
       "   'mfcc_std_5',\n",
       "   'mfcc_std_6',\n",
       "   'mfcc_std_7',\n",
       "   'mfcc_std_8',\n",
       "   'mfcc_std_9',\n",
       "   'mfcc_std_10',\n",
       "   'mfcc_std_11',\n",
       "   'mfcc_std_12',\n",
       "   'mfcc_std_13',\n",
       "   'mfcc_std_14',\n",
       "   'mfcc_std_15',\n",
       "   'mfcc_std_16',\n",
       "   'mfcc_std_17',\n",
       "   'mfcc_std_18',\n",
       "   'mfcc_std_19',\n",
       "   'mfcc_std_20',\n",
       "   'zcr_mean',\n",
       "   'zcr_median',\n",
       "   'zcr_std',\n",
       "   'zcr_p10',\n",
       "   'zcr_p90',\n",
       "   'HNR_stddev_hnr',\n",
       "   'HNR_mean_hnr',\n",
       "   'HNR_relative_min_hnr_time',\n",
       "   'HNR_max_hnr',\n",
       "   'Formant_f1_mean',\n",
       "   'Formant_f1_median',\n",
       "   'Formant_f3_mean',\n",
       "   'Formant_fitch_vtl',\n",
       "   'Formant_mff',\n",
       "   'Formant_formant_dispersion',\n",
       "   'rms_mean',\n",
       "   'rms_median',\n",
       "   'rms_std',\n",
       "   'rms_p10',\n",
       "   'rms_p90',\n",
       "   'Intensity_max_intensity',\n",
       "   'Intensity_q3_intensity',\n",
       "   'Intensity_median_intensity',\n",
       "   'Intensity_mean_intensity',\n",
       "   'Intensity_stddev_intensity',\n",
       "   'Intensity_relative_max_intensity_time',\n",
       "   'Pitch_pitch_slope_without_octave_jumps',\n",
       "   'Pitch_q3_pitch',\n",
       "   'Pitch_stddev_pitch',\n",
       "   'Pitch_mean_absolute_pitch_slope',\n",
       "   'Pitch_mean_pitch',\n",
       "   'Pitch_max_pitch',\n",
       "   'Pitch_q1_pitch',\n",
       "   'Pitch_min_pitch',\n",
       "   'Spectrum_band_energy_difference',\n",
       "   'Spectrum_band_density_difference',\n",
       "   'Spectrum_center_of_gravity_spectrum',\n",
       "   'Spectrum_skewness_spectrum',\n",
       "   'Spectrum_kurtosis_spectrum',\n",
       "   'Spectrum_stddev_spectrum',\n",
       "   'Spectrum_band_density',\n",
       "   'Spectrum_band_energy',\n",
       "   'Local Jitter',\n",
       "   'Local Shimmer']},\n",
       " RandomForestClassifier(min_samples_split=100, n_jobs=3, random_state=7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_84 = feature_MFCC20_mean + feature_MFCC20_std + feature_zcr_stats + selected_HNR + selected_formant + \\\n",
    "            feature_rms_stats + selected_intensity + selected_pitch + selected_spect+\\\n",
    "            ['Local Jitter','Local Shimmer']\n",
    "X_train = df_joint_train_aug[comb_84]\n",
    "X_test = df_joint_test[comb_84]\n",
    "exp_clf_with_feature_selected(rforest, X_train, X_test, y_train_e, y_test_e, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eaa733-2935-4b1d-a787-5b6a7912a554",
   "metadata": {
    "id": "11eaa733-2935-4b1d-a787-5b6a7912a554"
   },
   "source": [
    "### Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ed0f6-90f6-4f5c-9825-c9fc877abecc",
   "metadata": {
    "id": "657ed0f6-90f6-4f5c-9825-c9fc877abecc"
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy for the given threshold\n",
    "def calc_acc_by_thres(probabilities, threshold, y_test):\n",
    "    predictions_adj = []\n",
    "    # Loop through each sample's probabilities\n",
    "    for probs in probabilities:\n",
    "        if probs[0] > threshold:\n",
    "            pred_class = -1\n",
    "        elif probs[1] > probs[2]:\n",
    "            pred_class = 0\n",
    "        else:\n",
    "            pred_class = 1\n",
    "        predictions_adj.append(pred_class)\n",
    "    accuracy = np.mean(predictions_adj == y_test)\n",
    "    precision, recall, f1score, _ = precision_recall_fscore_support(y_test_s, predictions_adj, average=None)\n",
    "    return accuracy, min(f1score), np.var(f1score)\n",
    "\n",
    "best_threshold = None\n",
    "best_accuracy = 0.0\n",
    "best_f1score = 0.0\n",
    "# best_f1s_var = 10\n",
    "\n",
    "# Define a range of threshold values to try\n",
    "threshold_range = np.linspace(0.25, 0.75, 100)\n",
    "for threshold in threshold_range:\n",
    "    accuracy, min_f1_score, var_f1_score = calc_acc_by_thres(probabilities, threshold, y_test_s)\n",
    "    # if accuracy > best_accuracy:\n",
    "    #     best_accuracy = accuracy\n",
    "    #     best_threshold = threshold\n",
    "    if min_f1_score > best_f1score:\n",
    "        best_f1score = min_f1_score\n",
    "        best_threshold = threshold\n",
    "        best_accuracy = accuracy\n",
    "    # if var_f1_score < best_f1s_var:\n",
    "    #     best_f1score = min_f1_score\n",
    "    #     best_threshold = threshold\n",
    "    #     best_accuracy = accuracy\n",
    "    #     best_f1s_var = var_f1_score\n",
    "\n",
    "\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best min f1 score:\", best_f1score)\n",
    "# print(\"Best var f1 score:\", best_f1s_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4WQRLz5RIShR",
   "metadata": {
    "id": "4WQRLz5RIShR"
   },
   "source": [
    "## CNN Model\n",
    "data loading\n",
    "and model structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K0a_vxkGOjkF",
   "metadata": {
    "id": "K0a_vxkGOjkF"
   },
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bKkrEmbAIR7q",
   "metadata": {
    "id": "bKkrEmbAIR7q"
   },
   "outputs": [],
   "source": [
    "# Convert x_train to float32\n",
    "X_train_cnn = np.expand_dims(X_train, axis=2).astype(np.float32)\n",
    "y_train_e_cnn = y_train_e_num.astype(np.float32)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2).astype(np.float32)\n",
    "y_test_e_cnn = y_test_e_num.astype(np.float32)\n",
    "y_train_s_cnn = y_train_s.astype(np.float32)\n",
    "y_test_s_cnn = y_test_s.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "uYwiSVUEI0ij",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uYwiSVUEI0ij",
    "outputId": "0a8aec4c-9cb1-44c7-d91d-5101dfbf6be6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 131, 128)          768       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 131, 128)          0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 131, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 16, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 16, 128)           82048     \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 16, 128)           0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16, 128)           0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103306 (403.54 KB)\n",
      "Trainable params: 103306 (403.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "input_shape_1 = X_train_cnn.shape[1]\n",
    "model.add(Conv1D(128, 5,padding='same',input_shape=(input_shape_1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "# opt = keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None)  if use RMSprop, encountered error,I use Adam optimizers now\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "JXZWjCoKJc0y",
   "metadata": {
    "id": "JXZWjCoKJc0y"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),  # changed from opt to Adam()\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cY-N18uTPqTX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cY-N18uTPqTX",
    "outputId": "b38fe885-3833-44d7-fc7b-5dbae16b9118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "195/195 [==============================] - 2s 6ms/step - loss: 2.9921 - accuracy: 0.4418 - val_loss: 1.2821 - val_accuracy: 0.5485\n",
      "Epoch 2/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.2764 - accuracy: 0.5406 - val_loss: 1.2020 - val_accuracy: 0.5500\n",
      "Epoch 3/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.2045 - accuracy: 0.5687 - val_loss: 1.1877 - val_accuracy: 0.5353\n",
      "Epoch 4/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.1562 - accuracy: 0.5863 - val_loss: 1.1821 - val_accuracy: 0.5735\n",
      "Epoch 5/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 1.1242 - accuracy: 0.5950 - val_loss: 1.1056 - val_accuracy: 0.5941\n",
      "Epoch 6/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 1.0954 - accuracy: 0.6072 - val_loss: 1.1336 - val_accuracy: 0.6074\n",
      "Epoch 7/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.0658 - accuracy: 0.6168 - val_loss: 1.0952 - val_accuracy: 0.6015\n",
      "Epoch 8/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.0403 - accuracy: 0.6258 - val_loss: 1.0768 - val_accuracy: 0.6118\n",
      "Epoch 9/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.0322 - accuracy: 0.6287 - val_loss: 1.0328 - val_accuracy: 0.6191\n",
      "Epoch 10/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 1.0163 - accuracy: 0.6329 - val_loss: 1.0513 - val_accuracy: 0.5956\n",
      "Epoch 11/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9959 - accuracy: 0.6422 - val_loss: 1.0261 - val_accuracy: 0.6176\n",
      "Epoch 12/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9869 - accuracy: 0.6465 - val_loss: 1.0367 - val_accuracy: 0.5926\n",
      "Epoch 13/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9920 - accuracy: 0.6408 - val_loss: 1.0341 - val_accuracy: 0.6206\n",
      "Epoch 14/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9754 - accuracy: 0.6488 - val_loss: 1.0042 - val_accuracy: 0.5985\n",
      "Epoch 15/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9609 - accuracy: 0.6527 - val_loss: 1.0289 - val_accuracy: 0.6221\n",
      "Epoch 16/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9597 - accuracy: 0.6527 - val_loss: 1.0407 - val_accuracy: 0.6162\n",
      "Epoch 17/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9537 - accuracy: 0.6549 - val_loss: 1.0250 - val_accuracy: 0.6088\n",
      "Epoch 18/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9352 - accuracy: 0.6620 - val_loss: 1.0057 - val_accuracy: 0.6206\n",
      "Epoch 19/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.9316 - accuracy: 0.6658 - val_loss: 1.0057 - val_accuracy: 0.6147\n",
      "Epoch 20/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.9269 - accuracy: 0.6653 - val_loss: 1.0062 - val_accuracy: 0.6250\n",
      "Epoch 21/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9335 - accuracy: 0.6602 - val_loss: 1.0032 - val_accuracy: 0.6221\n",
      "Epoch 22/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9201 - accuracy: 0.6661 - val_loss: 1.0708 - val_accuracy: 0.6132\n",
      "Epoch 23/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9279 - accuracy: 0.6667 - val_loss: 0.9923 - val_accuracy: 0.6279\n",
      "Epoch 24/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9122 - accuracy: 0.6698 - val_loss: 0.9960 - val_accuracy: 0.6294\n",
      "Epoch 25/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8990 - accuracy: 0.6738 - val_loss: 0.9680 - val_accuracy: 0.6412\n",
      "Epoch 26/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.9052 - accuracy: 0.6710 - val_loss: 0.9913 - val_accuracy: 0.6250\n",
      "Epoch 27/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8970 - accuracy: 0.6754 - val_loss: 1.0031 - val_accuracy: 0.6250\n",
      "Epoch 28/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8993 - accuracy: 0.6739 - val_loss: 1.0393 - val_accuracy: 0.6074\n",
      "Epoch 29/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8866 - accuracy: 0.6783 - val_loss: 1.0118 - val_accuracy: 0.6206\n",
      "Epoch 30/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8873 - accuracy: 0.6770 - val_loss: 1.0050 - val_accuracy: 0.6382\n",
      "Epoch 31/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8817 - accuracy: 0.6811 - val_loss: 0.9749 - val_accuracy: 0.6206\n",
      "Epoch 32/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.8794 - accuracy: 0.6788 - val_loss: 0.9578 - val_accuracy: 0.6441\n",
      "Epoch 33/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.8810 - accuracy: 0.6807 - val_loss: 1.0183 - val_accuracy: 0.6132\n",
      "Epoch 34/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8733 - accuracy: 0.6843 - val_loss: 0.9926 - val_accuracy: 0.6338\n",
      "Epoch 35/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8796 - accuracy: 0.6799 - val_loss: 0.9695 - val_accuracy: 0.6426\n",
      "Epoch 36/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8615 - accuracy: 0.6883 - val_loss: 0.9506 - val_accuracy: 0.6338\n",
      "Epoch 37/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8684 - accuracy: 0.6865 - val_loss: 0.9774 - val_accuracy: 0.6235\n",
      "Epoch 38/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8585 - accuracy: 0.6885 - val_loss: 1.0204 - val_accuracy: 0.6176\n",
      "Epoch 39/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8600 - accuracy: 0.6891 - val_loss: 0.9511 - val_accuracy: 0.6529\n",
      "Epoch 40/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8532 - accuracy: 0.6868 - val_loss: 0.9605 - val_accuracy: 0.6368\n",
      "Epoch 41/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8501 - accuracy: 0.6937 - val_loss: 0.9433 - val_accuracy: 0.6559\n",
      "Epoch 42/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8460 - accuracy: 0.6929 - val_loss: 0.9597 - val_accuracy: 0.6412\n",
      "Epoch 43/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8473 - accuracy: 0.6922 - val_loss: 0.9709 - val_accuracy: 0.6368\n",
      "Epoch 44/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8370 - accuracy: 0.6957 - val_loss: 0.9499 - val_accuracy: 0.6676\n",
      "Epoch 45/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8399 - accuracy: 0.6970 - val_loss: 0.9706 - val_accuracy: 0.6397\n",
      "Epoch 46/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.8318 - accuracy: 0.6972 - val_loss: 0.9989 - val_accuracy: 0.6500\n",
      "Epoch 47/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.8376 - accuracy: 0.6964 - val_loss: 1.0385 - val_accuracy: 0.6074\n",
      "Epoch 48/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8314 - accuracy: 0.6971 - val_loss: 1.0028 - val_accuracy: 0.6250\n",
      "Epoch 49/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8263 - accuracy: 0.6991 - val_loss: 0.9724 - val_accuracy: 0.6412\n",
      "Epoch 50/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8210 - accuracy: 0.7005 - val_loss: 0.9709 - val_accuracy: 0.6397\n",
      "Epoch 51/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8230 - accuracy: 0.6995 - val_loss: 1.0111 - val_accuracy: 0.6324\n",
      "Epoch 52/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8204 - accuracy: 0.7005 - val_loss: 0.9779 - val_accuracy: 0.6368\n",
      "Epoch 53/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8182 - accuracy: 0.7042 - val_loss: 0.9928 - val_accuracy: 0.6368\n",
      "Epoch 54/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8135 - accuracy: 0.7030 - val_loss: 0.9614 - val_accuracy: 0.6309\n",
      "Epoch 55/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8102 - accuracy: 0.7058 - val_loss: 1.0374 - val_accuracy: 0.6132\n",
      "Epoch 56/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8184 - accuracy: 0.7019 - val_loss: 0.9685 - val_accuracy: 0.6265\n",
      "Epoch 57/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8187 - accuracy: 0.7022 - val_loss: 1.0077 - val_accuracy: 0.6206\n",
      "Epoch 58/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.8101 - accuracy: 0.7032 - val_loss: 1.0489 - val_accuracy: 0.6221\n",
      "Epoch 59/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.8129 - accuracy: 0.7037 - val_loss: 0.9689 - val_accuracy: 0.6471\n",
      "Epoch 60/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.8044 - accuracy: 0.7107 - val_loss: 1.0322 - val_accuracy: 0.6191\n",
      "Epoch 61/500\n",
      "195/195 [==============================] - 1s 8ms/step - loss: 0.7991 - accuracy: 0.7075 - val_loss: 0.9222 - val_accuracy: 0.6544\n",
      "Epoch 62/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.8001 - accuracy: 0.7087 - val_loss: 1.0678 - val_accuracy: 0.6103\n",
      "Epoch 63/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7979 - accuracy: 0.7090 - val_loss: 1.0015 - val_accuracy: 0.6235\n",
      "Epoch 64/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7984 - accuracy: 0.7090 - val_loss: 1.0240 - val_accuracy: 0.6191\n",
      "Epoch 65/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7934 - accuracy: 0.7103 - val_loss: 0.9965 - val_accuracy: 0.6338\n",
      "Epoch 66/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7939 - accuracy: 0.7101 - val_loss: 0.9866 - val_accuracy: 0.6559\n",
      "Epoch 67/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7995 - accuracy: 0.7101 - val_loss: 0.9886 - val_accuracy: 0.6353\n",
      "Epoch 68/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7939 - accuracy: 0.7117 - val_loss: 0.9386 - val_accuracy: 0.6574\n",
      "Epoch 69/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.7833 - accuracy: 0.7124 - val_loss: 0.9979 - val_accuracy: 0.6382\n",
      "Epoch 70/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7801 - accuracy: 0.7138 - val_loss: 1.0593 - val_accuracy: 0.6147\n",
      "Epoch 71/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7793 - accuracy: 0.7149 - val_loss: 0.9885 - val_accuracy: 0.6309\n",
      "Epoch 72/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7815 - accuracy: 0.7165 - val_loss: 0.9678 - val_accuracy: 0.6309\n",
      "Epoch 73/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7811 - accuracy: 0.7143 - val_loss: 0.9711 - val_accuracy: 0.6456\n",
      "Epoch 74/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7732 - accuracy: 0.7214 - val_loss: 0.9495 - val_accuracy: 0.6574\n",
      "Epoch 75/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7726 - accuracy: 0.7183 - val_loss: 1.0305 - val_accuracy: 0.6103\n",
      "Epoch 76/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7729 - accuracy: 0.7208 - val_loss: 1.0018 - val_accuracy: 0.6309\n",
      "Epoch 77/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7734 - accuracy: 0.7182 - val_loss: 1.0539 - val_accuracy: 0.6191\n",
      "Epoch 78/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7742 - accuracy: 0.7199 - val_loss: 0.9473 - val_accuracy: 0.6618\n",
      "Epoch 79/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7551 - accuracy: 0.7248 - val_loss: 0.9956 - val_accuracy: 0.6279\n",
      "Epoch 80/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7619 - accuracy: 0.7230 - val_loss: 0.9968 - val_accuracy: 0.6426\n",
      "Epoch 81/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7626 - accuracy: 0.7235 - val_loss: 1.0341 - val_accuracy: 0.6162\n",
      "Epoch 82/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7690 - accuracy: 0.7190 - val_loss: 0.9812 - val_accuracy: 0.6338\n",
      "Epoch 83/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7564 - accuracy: 0.7246 - val_loss: 0.9846 - val_accuracy: 0.6265\n",
      "Epoch 84/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7571 - accuracy: 0.7250 - val_loss: 0.9904 - val_accuracy: 0.6353\n",
      "Epoch 85/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7643 - accuracy: 0.7212 - val_loss: 0.9799 - val_accuracy: 0.6412\n",
      "Epoch 86/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7507 - accuracy: 0.7277 - val_loss: 0.9695 - val_accuracy: 0.6412\n",
      "Epoch 87/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7576 - accuracy: 0.7232 - val_loss: 0.9711 - val_accuracy: 0.6500\n",
      "Epoch 88/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7550 - accuracy: 0.7236 - val_loss: 0.9696 - val_accuracy: 0.6456\n",
      "Epoch 89/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7472 - accuracy: 0.7251 - val_loss: 0.9867 - val_accuracy: 0.6412\n",
      "Epoch 90/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7486 - accuracy: 0.7276 - val_loss: 0.9733 - val_accuracy: 0.6309\n",
      "Epoch 91/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7511 - accuracy: 0.7284 - val_loss: 0.9988 - val_accuracy: 0.6485\n",
      "Epoch 92/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7500 - accuracy: 0.7273 - val_loss: 0.9999 - val_accuracy: 0.6632\n",
      "Epoch 93/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7478 - accuracy: 0.7259 - val_loss: 1.0388 - val_accuracy: 0.6265\n",
      "Epoch 94/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7445 - accuracy: 0.7284 - val_loss: 1.0325 - val_accuracy: 0.6426\n",
      "Epoch 95/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7444 - accuracy: 0.7273 - val_loss: 0.9713 - val_accuracy: 0.6574\n",
      "Epoch 96/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7427 - accuracy: 0.7309 - val_loss: 1.0273 - val_accuracy: 0.6426\n",
      "Epoch 97/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7358 - accuracy: 0.7324 - val_loss: 1.0070 - val_accuracy: 0.6544\n",
      "Epoch 98/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7394 - accuracy: 0.7292 - val_loss: 1.0124 - val_accuracy: 0.6471\n",
      "Epoch 99/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7394 - accuracy: 0.7299 - val_loss: 1.0160 - val_accuracy: 0.6368\n",
      "Epoch 100/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7264 - accuracy: 0.7333 - val_loss: 1.0546 - val_accuracy: 0.6441\n",
      "Epoch 101/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7401 - accuracy: 0.7288 - val_loss: 0.9793 - val_accuracy: 0.6456\n",
      "Epoch 102/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7365 - accuracy: 0.7335 - val_loss: 1.0627 - val_accuracy: 0.6206\n",
      "Epoch 103/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7346 - accuracy: 0.7321 - val_loss: 1.0806 - val_accuracy: 0.6265\n",
      "Epoch 104/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7408 - accuracy: 0.7304 - val_loss: 1.0619 - val_accuracy: 0.6426\n",
      "Epoch 105/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7230 - accuracy: 0.7361 - val_loss: 0.9945 - val_accuracy: 0.6426\n",
      "Epoch 106/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7239 - accuracy: 0.7363 - val_loss: 1.0041 - val_accuracy: 0.6500\n",
      "Epoch 107/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7128 - accuracy: 0.7388 - val_loss: 1.0128 - val_accuracy: 0.6559\n",
      "Epoch 108/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7296 - accuracy: 0.7349 - val_loss: 1.0529 - val_accuracy: 0.6000\n",
      "Epoch 109/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7200 - accuracy: 0.7373 - val_loss: 1.0342 - val_accuracy: 0.6559\n",
      "Epoch 110/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7181 - accuracy: 0.7405 - val_loss: 1.0554 - val_accuracy: 0.6235\n",
      "Epoch 111/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7192 - accuracy: 0.7381 - val_loss: 1.1174 - val_accuracy: 0.6221\n",
      "Epoch 112/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7200 - accuracy: 0.7388 - val_loss: 1.0665 - val_accuracy: 0.6118\n",
      "Epoch 113/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7045 - accuracy: 0.7425 - val_loss: 1.0839 - val_accuracy: 0.6191\n",
      "Epoch 114/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.7201 - accuracy: 0.7377 - val_loss: 1.0167 - val_accuracy: 0.6235\n",
      "Epoch 115/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7126 - accuracy: 0.7414 - val_loss: 1.0983 - val_accuracy: 0.6132\n",
      "Epoch 116/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7109 - accuracy: 0.7408 - val_loss: 1.0138 - val_accuracy: 0.6309\n",
      "Epoch 117/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7102 - accuracy: 0.7392 - val_loss: 1.0530 - val_accuracy: 0.6382\n",
      "Epoch 118/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7084 - accuracy: 0.7412 - val_loss: 1.0807 - val_accuracy: 0.6265\n",
      "Epoch 119/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7112 - accuracy: 0.7408 - val_loss: 1.0545 - val_accuracy: 0.6397\n",
      "Epoch 120/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7077 - accuracy: 0.7395 - val_loss: 1.0083 - val_accuracy: 0.6397\n",
      "Epoch 121/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7023 - accuracy: 0.7447 - val_loss: 1.0116 - val_accuracy: 0.6485\n",
      "Epoch 122/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7078 - accuracy: 0.7424 - val_loss: 1.0200 - val_accuracy: 0.6235\n",
      "Epoch 123/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7101 - accuracy: 0.7408 - val_loss: 1.0173 - val_accuracy: 0.6382\n",
      "Epoch 124/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6995 - accuracy: 0.7451 - val_loss: 1.0711 - val_accuracy: 0.6426\n",
      "Epoch 125/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.7033 - accuracy: 0.7450 - val_loss: 0.9991 - val_accuracy: 0.6471\n",
      "Epoch 126/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6933 - accuracy: 0.7474 - val_loss: 1.0522 - val_accuracy: 0.6324\n",
      "Epoch 127/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6939 - accuracy: 0.7467 - val_loss: 1.0779 - val_accuracy: 0.6221\n",
      "Epoch 128/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6943 - accuracy: 0.7453 - val_loss: 1.0005 - val_accuracy: 0.6338\n",
      "Epoch 129/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6990 - accuracy: 0.7452 - val_loss: 1.0501 - val_accuracy: 0.6426\n",
      "Epoch 130/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6972 - accuracy: 0.7457 - val_loss: 1.0480 - val_accuracy: 0.6412\n",
      "Epoch 131/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6959 - accuracy: 0.7461 - val_loss: 1.0384 - val_accuracy: 0.6324\n",
      "Epoch 132/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6948 - accuracy: 0.7476 - val_loss: 1.0038 - val_accuracy: 0.6618\n",
      "Epoch 133/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6890 - accuracy: 0.7479 - val_loss: 1.1093 - val_accuracy: 0.6294\n",
      "Epoch 134/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6917 - accuracy: 0.7483 - val_loss: 1.0579 - val_accuracy: 0.6500\n",
      "Epoch 135/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6834 - accuracy: 0.7494 - val_loss: 1.1133 - val_accuracy: 0.6235\n",
      "Epoch 136/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6895 - accuracy: 0.7502 - val_loss: 1.1751 - val_accuracy: 0.6000\n",
      "Epoch 137/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6879 - accuracy: 0.7490 - val_loss: 1.0146 - val_accuracy: 0.6426\n",
      "Epoch 138/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6787 - accuracy: 0.7535 - val_loss: 1.1029 - val_accuracy: 0.6250\n",
      "Epoch 139/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6856 - accuracy: 0.7518 - val_loss: 1.0325 - val_accuracy: 0.6426\n",
      "Epoch 140/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6821 - accuracy: 0.7532 - val_loss: 1.0812 - val_accuracy: 0.6324\n",
      "Epoch 141/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6736 - accuracy: 0.7551 - val_loss: 1.0454 - val_accuracy: 0.6426\n",
      "Epoch 142/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6796 - accuracy: 0.7531 - val_loss: 1.0488 - val_accuracy: 0.6368\n",
      "Epoch 143/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6824 - accuracy: 0.7517 - val_loss: 1.0713 - val_accuracy: 0.6324\n",
      "Epoch 144/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6804 - accuracy: 0.7525 - val_loss: 1.1161 - val_accuracy: 0.6044\n",
      "Epoch 145/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6801 - accuracy: 0.7524 - val_loss: 1.1178 - val_accuracy: 0.6147\n",
      "Epoch 146/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6730 - accuracy: 0.7561 - val_loss: 1.0738 - val_accuracy: 0.6324\n",
      "Epoch 147/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6727 - accuracy: 0.7559 - val_loss: 1.0600 - val_accuracy: 0.6471\n",
      "Epoch 148/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6706 - accuracy: 0.7569 - val_loss: 1.0935 - val_accuracy: 0.6250\n",
      "Epoch 149/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6781 - accuracy: 0.7565 - val_loss: 1.0599 - val_accuracy: 0.6176\n",
      "Epoch 150/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6727 - accuracy: 0.7533 - val_loss: 1.0651 - val_accuracy: 0.6206\n",
      "Epoch 151/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6614 - accuracy: 0.7576 - val_loss: 1.1129 - val_accuracy: 0.6324\n",
      "Epoch 152/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6710 - accuracy: 0.7578 - val_loss: 1.1144 - val_accuracy: 0.6279\n",
      "Epoch 153/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6766 - accuracy: 0.7531 - val_loss: 1.0420 - val_accuracy: 0.6544\n",
      "Epoch 154/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6725 - accuracy: 0.7544 - val_loss: 1.1100 - val_accuracy: 0.6132\n",
      "Epoch 155/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6650 - accuracy: 0.7574 - val_loss: 1.0520 - val_accuracy: 0.6500\n",
      "Epoch 156/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6748 - accuracy: 0.7543 - val_loss: 1.1394 - val_accuracy: 0.6132\n",
      "Epoch 157/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6626 - accuracy: 0.7607 - val_loss: 1.0445 - val_accuracy: 0.6368\n",
      "Epoch 158/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6692 - accuracy: 0.7540 - val_loss: 1.1221 - val_accuracy: 0.6294\n",
      "Epoch 159/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6646 - accuracy: 0.7578 - val_loss: 1.1326 - val_accuracy: 0.6074\n",
      "Epoch 160/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6625 - accuracy: 0.7595 - val_loss: 1.1402 - val_accuracy: 0.6235\n",
      "Epoch 161/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6623 - accuracy: 0.7597 - val_loss: 1.1031 - val_accuracy: 0.6426\n",
      "Epoch 162/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6515 - accuracy: 0.7619 - val_loss: 1.0931 - val_accuracy: 0.6353\n",
      "Epoch 163/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6660 - accuracy: 0.7568 - val_loss: 1.1383 - val_accuracy: 0.6559\n",
      "Epoch 164/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6619 - accuracy: 0.7599 - val_loss: 1.0713 - val_accuracy: 0.6441\n",
      "Epoch 165/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6559 - accuracy: 0.7604 - val_loss: 1.0639 - val_accuracy: 0.6368\n",
      "Epoch 166/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6614 - accuracy: 0.7588 - val_loss: 1.0809 - val_accuracy: 0.6574\n",
      "Epoch 167/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6562 - accuracy: 0.7608 - val_loss: 1.2155 - val_accuracy: 0.6176\n",
      "Epoch 168/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6538 - accuracy: 0.7613 - val_loss: 1.0238 - val_accuracy: 0.6353\n",
      "Epoch 169/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6503 - accuracy: 0.7640 - val_loss: 1.1826 - val_accuracy: 0.6294\n",
      "Epoch 170/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6615 - accuracy: 0.7583 - val_loss: 1.1363 - val_accuracy: 0.6279\n",
      "Epoch 171/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6543 - accuracy: 0.7639 - val_loss: 1.1311 - val_accuracy: 0.6235\n",
      "Epoch 172/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6504 - accuracy: 0.7633 - val_loss: 1.1420 - val_accuracy: 0.6250\n",
      "Epoch 173/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6563 - accuracy: 0.7629 - val_loss: 1.2073 - val_accuracy: 0.6132\n",
      "Epoch 174/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6575 - accuracy: 0.7619 - val_loss: 1.1095 - val_accuracy: 0.6382\n",
      "Epoch 175/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6517 - accuracy: 0.7621 - val_loss: 1.1781 - val_accuracy: 0.6338\n",
      "Epoch 176/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6448 - accuracy: 0.7660 - val_loss: 1.1391 - val_accuracy: 0.6294\n",
      "Epoch 177/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.6411 - accuracy: 0.7679 - val_loss: 1.0936 - val_accuracy: 0.6176\n",
      "Epoch 178/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.7683 - val_loss: 1.1457 - val_accuracy: 0.6500\n",
      "Epoch 179/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6494 - accuracy: 0.7634 - val_loss: 1.1093 - val_accuracy: 0.6176\n",
      "Epoch 180/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6457 - accuracy: 0.7648 - val_loss: 1.1361 - val_accuracy: 0.6279\n",
      "Epoch 181/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.6417 - accuracy: 0.7666 - val_loss: 1.1163 - val_accuracy: 0.6279\n",
      "Epoch 182/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6428 - accuracy: 0.7628 - val_loss: 1.1046 - val_accuracy: 0.6368\n",
      "Epoch 183/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6371 - accuracy: 0.7685 - val_loss: 1.1324 - val_accuracy: 0.6382\n",
      "Epoch 184/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.7692 - val_loss: 1.1068 - val_accuracy: 0.6324\n",
      "Epoch 185/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6406 - accuracy: 0.7686 - val_loss: 1.1820 - val_accuracy: 0.6015\n",
      "Epoch 186/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6521 - accuracy: 0.7618 - val_loss: 1.2210 - val_accuracy: 0.6044\n",
      "Epoch 187/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6401 - accuracy: 0.7677 - val_loss: 1.1291 - val_accuracy: 0.6206\n",
      "Epoch 188/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.7683 - val_loss: 1.1559 - val_accuracy: 0.6162\n",
      "Epoch 189/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6325 - accuracy: 0.7695 - val_loss: 1.1680 - val_accuracy: 0.6147\n",
      "Epoch 190/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.7683 - val_loss: 1.1929 - val_accuracy: 0.5971\n",
      "Epoch 191/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6313 - accuracy: 0.7692 - val_loss: 1.1500 - val_accuracy: 0.6147\n",
      "Epoch 192/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.7675 - val_loss: 1.1110 - val_accuracy: 0.6279\n",
      "Epoch 193/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6423 - accuracy: 0.7660 - val_loss: 1.1261 - val_accuracy: 0.6044\n",
      "Epoch 194/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6301 - accuracy: 0.7684 - val_loss: 1.0900 - val_accuracy: 0.6132\n",
      "Epoch 195/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6379 - accuracy: 0.7678 - val_loss: 1.1176 - val_accuracy: 0.6368\n",
      "Epoch 196/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6355 - accuracy: 0.7693 - val_loss: 1.0961 - val_accuracy: 0.6382\n",
      "Epoch 197/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6306 - accuracy: 0.7725 - val_loss: 1.1519 - val_accuracy: 0.6147\n",
      "Epoch 198/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6326 - accuracy: 0.7684 - val_loss: 1.0722 - val_accuracy: 0.6368\n",
      "Epoch 199/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6314 - accuracy: 0.7697 - val_loss: 1.1429 - val_accuracy: 0.6324\n",
      "Epoch 200/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6370 - accuracy: 0.7665 - val_loss: 1.1516 - val_accuracy: 0.6206\n",
      "Epoch 201/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6251 - accuracy: 0.7744 - val_loss: 1.1357 - val_accuracy: 0.6309\n",
      "Epoch 202/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6238 - accuracy: 0.7759 - val_loss: 1.0916 - val_accuracy: 0.6471\n",
      "Epoch 203/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.7683 - val_loss: 1.1926 - val_accuracy: 0.6221\n",
      "Epoch 204/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6287 - accuracy: 0.7707 - val_loss: 1.1455 - val_accuracy: 0.5868\n",
      "Epoch 205/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6320 - accuracy: 0.7715 - val_loss: 1.1516 - val_accuracy: 0.6221\n",
      "Epoch 206/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6224 - accuracy: 0.7750 - val_loss: 1.1271 - val_accuracy: 0.6235\n",
      "Epoch 207/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6237 - accuracy: 0.7738 - val_loss: 1.1677 - val_accuracy: 0.6250\n",
      "Epoch 208/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6392 - accuracy: 0.7705 - val_loss: 1.1456 - val_accuracy: 0.6338\n",
      "Epoch 209/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.7751 - val_loss: 1.2026 - val_accuracy: 0.6118\n",
      "Epoch 210/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6254 - accuracy: 0.7746 - val_loss: 1.1848 - val_accuracy: 0.6265\n",
      "Epoch 211/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6234 - accuracy: 0.7721 - val_loss: 1.1922 - val_accuracy: 0.6103\n",
      "Epoch 212/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6233 - accuracy: 0.7720 - val_loss: 1.2373 - val_accuracy: 0.6221\n",
      "Epoch 213/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6128 - accuracy: 0.7777 - val_loss: 1.1422 - val_accuracy: 0.5985\n",
      "Epoch 214/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.7751 - val_loss: 1.1603 - val_accuracy: 0.6206\n",
      "Epoch 215/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6255 - accuracy: 0.7713 - val_loss: 1.1115 - val_accuracy: 0.6265\n",
      "Epoch 216/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6212 - accuracy: 0.7733 - val_loss: 1.1555 - val_accuracy: 0.6206\n",
      "Epoch 217/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6249 - accuracy: 0.7685 - val_loss: 1.1692 - val_accuracy: 0.6162\n",
      "Epoch 218/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6217 - accuracy: 0.7734 - val_loss: 1.2333 - val_accuracy: 0.6221\n",
      "Epoch 219/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.7748 - val_loss: 1.2246 - val_accuracy: 0.6029\n",
      "Epoch 220/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6142 - accuracy: 0.7761 - val_loss: 1.1429 - val_accuracy: 0.6235\n",
      "Epoch 221/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6195 - accuracy: 0.7734 - val_loss: 1.1425 - val_accuracy: 0.6324\n",
      "Epoch 222/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6140 - accuracy: 0.7772 - val_loss: 1.1481 - val_accuracy: 0.6412\n",
      "Epoch 223/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6177 - accuracy: 0.7765 - val_loss: 1.1470 - val_accuracy: 0.6353\n",
      "Epoch 224/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6166 - accuracy: 0.7788 - val_loss: 1.1671 - val_accuracy: 0.6250\n",
      "Epoch 225/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7748 - val_loss: 1.1475 - val_accuracy: 0.6176\n",
      "Epoch 226/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6164 - accuracy: 0.7761 - val_loss: 1.2067 - val_accuracy: 0.6221\n",
      "Epoch 227/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6218 - accuracy: 0.7738 - val_loss: 1.2003 - val_accuracy: 0.6206\n",
      "Epoch 228/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6147 - accuracy: 0.7747 - val_loss: 1.1910 - val_accuracy: 0.6118\n",
      "Epoch 229/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6236 - accuracy: 0.7740 - val_loss: 1.1205 - val_accuracy: 0.6309\n",
      "Epoch 230/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6205 - accuracy: 0.7752 - val_loss: 1.1830 - val_accuracy: 0.6118\n",
      "Epoch 231/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.7771 - val_loss: 1.1496 - val_accuracy: 0.6294\n",
      "Epoch 232/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.7781 - val_loss: 1.1301 - val_accuracy: 0.6147\n",
      "Epoch 233/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6113 - accuracy: 0.7776 - val_loss: 1.0991 - val_accuracy: 0.6397\n",
      "Epoch 234/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6069 - accuracy: 0.7795 - val_loss: 1.1291 - val_accuracy: 0.6162\n",
      "Epoch 235/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6095 - accuracy: 0.7756 - val_loss: 1.2376 - val_accuracy: 0.6044\n",
      "Epoch 236/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6113 - accuracy: 0.7763 - val_loss: 1.1239 - val_accuracy: 0.6147\n",
      "Epoch 237/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6119 - accuracy: 0.7778 - val_loss: 1.1754 - val_accuracy: 0.5926\n",
      "Epoch 238/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6098 - accuracy: 0.7764 - val_loss: 1.1466 - val_accuracy: 0.6118\n",
      "Epoch 239/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6096 - accuracy: 0.7795 - val_loss: 1.1682 - val_accuracy: 0.6265\n",
      "Epoch 240/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6060 - accuracy: 0.7838 - val_loss: 1.1731 - val_accuracy: 0.6265\n",
      "Epoch 241/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6118 - accuracy: 0.7764 - val_loss: 1.1339 - val_accuracy: 0.6000\n",
      "Epoch 242/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6142 - accuracy: 0.7749 - val_loss: 1.2061 - val_accuracy: 0.6206\n",
      "Epoch 243/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6046 - accuracy: 0.7820 - val_loss: 1.1254 - val_accuracy: 0.6368\n",
      "Epoch 244/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6092 - accuracy: 0.7769 - val_loss: 1.1998 - val_accuracy: 0.6250\n",
      "Epoch 245/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6105 - accuracy: 0.7762 - val_loss: 1.1797 - val_accuracy: 0.6221\n",
      "Epoch 246/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6047 - accuracy: 0.7799 - val_loss: 1.1383 - val_accuracy: 0.6309\n",
      "Epoch 247/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5991 - accuracy: 0.7818 - val_loss: 1.1885 - val_accuracy: 0.6309\n",
      "Epoch 248/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6128 - accuracy: 0.7752 - val_loss: 1.2507 - val_accuracy: 0.6235\n",
      "Epoch 249/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6073 - accuracy: 0.7793 - val_loss: 1.1530 - val_accuracy: 0.6059\n",
      "Epoch 250/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5999 - accuracy: 0.7798 - val_loss: 1.3141 - val_accuracy: 0.5853\n",
      "Epoch 251/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5982 - accuracy: 0.7827 - val_loss: 1.1677 - val_accuracy: 0.6162\n",
      "Epoch 252/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.7838 - val_loss: 1.2119 - val_accuracy: 0.6147\n",
      "Epoch 253/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6016 - accuracy: 0.7822 - val_loss: 1.1618 - val_accuracy: 0.6368\n",
      "Epoch 254/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6029 - accuracy: 0.7812 - val_loss: 1.1480 - val_accuracy: 0.6368\n",
      "Epoch 255/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6006 - accuracy: 0.7811 - val_loss: 1.1718 - val_accuracy: 0.6191\n",
      "Epoch 256/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5941 - accuracy: 0.7851 - val_loss: 1.2251 - val_accuracy: 0.6176\n",
      "Epoch 257/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6129 - accuracy: 0.7784 - val_loss: 1.2559 - val_accuracy: 0.6147\n",
      "Epoch 258/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.7816 - val_loss: 1.1580 - val_accuracy: 0.6368\n",
      "Epoch 259/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5917 - accuracy: 0.7848 - val_loss: 1.1720 - val_accuracy: 0.6265\n",
      "Epoch 260/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6037 - accuracy: 0.7812 - val_loss: 1.1861 - val_accuracy: 0.6044\n",
      "Epoch 261/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5974 - accuracy: 0.7844 - val_loss: 1.2299 - val_accuracy: 0.6279\n",
      "Epoch 262/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6003 - accuracy: 0.7789 - val_loss: 1.1725 - val_accuracy: 0.6338\n",
      "Epoch 263/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.6001 - accuracy: 0.7832 - val_loss: 1.1305 - val_accuracy: 0.6353\n",
      "Epoch 264/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5999 - accuracy: 0.7791 - val_loss: 1.1907 - val_accuracy: 0.6162\n",
      "Epoch 265/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5938 - accuracy: 0.7839 - val_loss: 1.2189 - val_accuracy: 0.6279\n",
      "Epoch 266/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5944 - accuracy: 0.7806 - val_loss: 1.2445 - val_accuracy: 0.6118\n",
      "Epoch 267/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5980 - accuracy: 0.7849 - val_loss: 1.1852 - val_accuracy: 0.6382\n",
      "Epoch 268/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5916 - accuracy: 0.7858 - val_loss: 1.1917 - val_accuracy: 0.6294\n",
      "Epoch 269/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5964 - accuracy: 0.7857 - val_loss: 1.1715 - val_accuracy: 0.6456\n",
      "Epoch 270/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5915 - accuracy: 0.7864 - val_loss: 1.1626 - val_accuracy: 0.6250\n",
      "Epoch 271/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5991 - accuracy: 0.7812 - val_loss: 1.1841 - val_accuracy: 0.6309\n",
      "Epoch 272/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5937 - accuracy: 0.7834 - val_loss: 1.2079 - val_accuracy: 0.6088\n",
      "Epoch 273/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5954 - accuracy: 0.7836 - val_loss: 1.3105 - val_accuracy: 0.6206\n",
      "Epoch 274/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5934 - accuracy: 0.7859 - val_loss: 1.2925 - val_accuracy: 0.6162\n",
      "Epoch 275/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5879 - accuracy: 0.7865 - val_loss: 1.2185 - val_accuracy: 0.6132\n",
      "Epoch 276/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5904 - accuracy: 0.7836 - val_loss: 1.1954 - val_accuracy: 0.6235\n",
      "Epoch 277/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5911 - accuracy: 0.7828 - val_loss: 1.2917 - val_accuracy: 0.6147\n",
      "Epoch 278/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5923 - accuracy: 0.7854 - val_loss: 1.1356 - val_accuracy: 0.6279\n",
      "Epoch 279/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5901 - accuracy: 0.7861 - val_loss: 1.2185 - val_accuracy: 0.6088\n",
      "Epoch 280/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5856 - accuracy: 0.7864 - val_loss: 1.2645 - val_accuracy: 0.6000\n",
      "Epoch 281/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5894 - accuracy: 0.7851 - val_loss: 1.3159 - val_accuracy: 0.5971\n",
      "Epoch 282/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5820 - accuracy: 0.7882 - val_loss: 1.2853 - val_accuracy: 0.6191\n",
      "Epoch 283/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5910 - accuracy: 0.7871 - val_loss: 1.2081 - val_accuracy: 0.6162\n",
      "Epoch 284/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5967 - accuracy: 0.7808 - val_loss: 1.2049 - val_accuracy: 0.6382\n",
      "Epoch 285/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5969 - accuracy: 0.7812 - val_loss: 1.2375 - val_accuracy: 0.6132\n",
      "Epoch 286/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.7903 - val_loss: 1.2500 - val_accuracy: 0.6191\n",
      "Epoch 287/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5869 - accuracy: 0.7870 - val_loss: 1.3066 - val_accuracy: 0.6162\n",
      "Epoch 288/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.6038 - accuracy: 0.7811 - val_loss: 1.2420 - val_accuracy: 0.6118\n",
      "Epoch 289/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5884 - accuracy: 0.7856 - val_loss: 1.2306 - val_accuracy: 0.6279\n",
      "Epoch 290/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5842 - accuracy: 0.7885 - val_loss: 1.2687 - val_accuracy: 0.6103\n",
      "Epoch 291/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5805 - accuracy: 0.7887 - val_loss: 1.2299 - val_accuracy: 0.6235\n",
      "Epoch 292/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5753 - accuracy: 0.7897 - val_loss: 1.2286 - val_accuracy: 0.6206\n",
      "Epoch 293/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5823 - accuracy: 0.7867 - val_loss: 1.2281 - val_accuracy: 0.6088\n",
      "Epoch 294/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5898 - accuracy: 0.7832 - val_loss: 1.2922 - val_accuracy: 0.6103\n",
      "Epoch 295/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5795 - accuracy: 0.7895 - val_loss: 1.2952 - val_accuracy: 0.6206\n",
      "Epoch 296/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5838 - accuracy: 0.7854 - val_loss: 1.2152 - val_accuracy: 0.6132\n",
      "Epoch 297/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5777 - accuracy: 0.7881 - val_loss: 1.3162 - val_accuracy: 0.6074\n",
      "Epoch 298/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5718 - accuracy: 0.7914 - val_loss: 1.2233 - val_accuracy: 0.6118\n",
      "Epoch 299/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5862 - accuracy: 0.7876 - val_loss: 1.2968 - val_accuracy: 0.6132\n",
      "Epoch 300/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5849 - accuracy: 0.7869 - val_loss: 1.2672 - val_accuracy: 0.6221\n",
      "Epoch 301/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5740 - accuracy: 0.7920 - val_loss: 1.1961 - val_accuracy: 0.6309\n",
      "Epoch 302/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5927 - accuracy: 0.7840 - val_loss: 1.2923 - val_accuracy: 0.6162\n",
      "Epoch 303/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5752 - accuracy: 0.7909 - val_loss: 1.2062 - val_accuracy: 0.6132\n",
      "Epoch 304/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.7859 - val_loss: 1.2592 - val_accuracy: 0.6132\n",
      "Epoch 305/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5817 - accuracy: 0.7886 - val_loss: 1.2010 - val_accuracy: 0.6162\n",
      "Epoch 306/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5742 - accuracy: 0.7892 - val_loss: 1.2468 - val_accuracy: 0.6353\n",
      "Epoch 307/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5779 - accuracy: 0.7898 - val_loss: 1.2596 - val_accuracy: 0.6088\n",
      "Epoch 308/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5801 - accuracy: 0.7912 - val_loss: 1.2295 - val_accuracy: 0.6324\n",
      "Epoch 309/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5717 - accuracy: 0.7917 - val_loss: 1.2562 - val_accuracy: 0.6103\n",
      "Epoch 310/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5700 - accuracy: 0.7915 - val_loss: 1.2740 - val_accuracy: 0.6176\n",
      "Epoch 311/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5669 - accuracy: 0.7927 - val_loss: 1.2880 - val_accuracy: 0.6324\n",
      "Epoch 312/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5739 - accuracy: 0.7894 - val_loss: 1.3060 - val_accuracy: 0.6103\n",
      "Epoch 313/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5744 - accuracy: 0.7898 - val_loss: 1.2468 - val_accuracy: 0.6221\n",
      "Epoch 314/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5799 - accuracy: 0.7880 - val_loss: 1.3401 - val_accuracy: 0.6294\n",
      "Epoch 315/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5701 - accuracy: 0.7939 - val_loss: 1.2448 - val_accuracy: 0.6265\n",
      "Epoch 316/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5689 - accuracy: 0.7939 - val_loss: 1.2876 - val_accuracy: 0.6103\n",
      "Epoch 317/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.7918 - val_loss: 1.2913 - val_accuracy: 0.5985\n",
      "Epoch 318/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5685 - accuracy: 0.7912 - val_loss: 1.2983 - val_accuracy: 0.6265\n",
      "Epoch 319/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5755 - accuracy: 0.7919 - val_loss: 1.2777 - val_accuracy: 0.6118\n",
      "Epoch 320/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5796 - accuracy: 0.7887 - val_loss: 1.2381 - val_accuracy: 0.6338\n",
      "Epoch 321/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5739 - accuracy: 0.7948 - val_loss: 1.2789 - val_accuracy: 0.6088\n",
      "Epoch 322/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5787 - accuracy: 0.7900 - val_loss: 1.2361 - val_accuracy: 0.6265\n",
      "Epoch 323/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5753 - accuracy: 0.7913 - val_loss: 1.2424 - val_accuracy: 0.6191\n",
      "Epoch 324/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5657 - accuracy: 0.7938 - val_loss: 1.1879 - val_accuracy: 0.6206\n",
      "Epoch 325/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5841 - accuracy: 0.7891 - val_loss: 1.2758 - val_accuracy: 0.6059\n",
      "Epoch 326/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5741 - accuracy: 0.7937 - val_loss: 1.3034 - val_accuracy: 0.6147\n",
      "Epoch 327/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5760 - accuracy: 0.7903 - val_loss: 1.2310 - val_accuracy: 0.6235\n",
      "Epoch 328/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5798 - accuracy: 0.7907 - val_loss: 1.2453 - val_accuracy: 0.6324\n",
      "Epoch 329/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5701 - accuracy: 0.7925 - val_loss: 1.3078 - val_accuracy: 0.6324\n",
      "Epoch 330/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5725 - accuracy: 0.7914 - val_loss: 1.2330 - val_accuracy: 0.6191\n",
      "Epoch 331/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5656 - accuracy: 0.7932 - val_loss: 1.2956 - val_accuracy: 0.6015\n",
      "Epoch 332/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5687 - accuracy: 0.7922 - val_loss: 1.2750 - val_accuracy: 0.6044\n",
      "Epoch 333/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5724 - accuracy: 0.7914 - val_loss: 1.2429 - val_accuracy: 0.6044\n",
      "Epoch 334/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.7962 - val_loss: 1.3192 - val_accuracy: 0.6162\n",
      "Epoch 335/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5709 - accuracy: 0.7902 - val_loss: 1.2466 - val_accuracy: 0.6029\n",
      "Epoch 336/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5738 - accuracy: 0.7909 - val_loss: 1.2275 - val_accuracy: 0.6221\n",
      "Epoch 337/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5618 - accuracy: 0.7986 - val_loss: 1.3242 - val_accuracy: 0.6059\n",
      "Epoch 338/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5666 - accuracy: 0.7942 - val_loss: 1.2451 - val_accuracy: 0.6279\n",
      "Epoch 339/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5641 - accuracy: 0.7971 - val_loss: 1.2833 - val_accuracy: 0.5882\n",
      "Epoch 340/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5753 - accuracy: 0.7919 - val_loss: 1.2603 - val_accuracy: 0.6162\n",
      "Epoch 341/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5709 - accuracy: 0.7916 - val_loss: 1.2356 - val_accuracy: 0.6162\n",
      "Epoch 342/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5641 - accuracy: 0.7939 - val_loss: 1.1782 - val_accuracy: 0.6397\n",
      "Epoch 343/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7943 - val_loss: 1.2607 - val_accuracy: 0.6162\n",
      "Epoch 344/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5709 - accuracy: 0.7934 - val_loss: 1.3347 - val_accuracy: 0.6132\n",
      "Epoch 345/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5607 - accuracy: 0.7949 - val_loss: 1.2253 - val_accuracy: 0.6265\n",
      "Epoch 346/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5779 - accuracy: 0.7894 - val_loss: 1.2642 - val_accuracy: 0.6250\n",
      "Epoch 347/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5615 - accuracy: 0.7973 - val_loss: 1.3476 - val_accuracy: 0.5897\n",
      "Epoch 348/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5598 - accuracy: 0.7989 - val_loss: 1.2824 - val_accuracy: 0.6191\n",
      "Epoch 349/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.7976 - val_loss: 1.2874 - val_accuracy: 0.6235\n",
      "Epoch 350/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5633 - accuracy: 0.7949 - val_loss: 1.1900 - val_accuracy: 0.6353\n",
      "Epoch 351/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5653 - accuracy: 0.7933 - val_loss: 1.2480 - val_accuracy: 0.6176\n",
      "Epoch 352/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5587 - accuracy: 0.7975 - val_loss: 1.2843 - val_accuracy: 0.6088\n",
      "Epoch 353/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5603 - accuracy: 0.7940 - val_loss: 1.2605 - val_accuracy: 0.6147\n",
      "Epoch 354/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5582 - accuracy: 0.7998 - val_loss: 1.2809 - val_accuracy: 0.6103\n",
      "Epoch 355/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5612 - accuracy: 0.7965 - val_loss: 1.2574 - val_accuracy: 0.6191\n",
      "Epoch 356/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5571 - accuracy: 0.7996 - val_loss: 1.2373 - val_accuracy: 0.6368\n",
      "Epoch 357/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.7890 - val_loss: 1.3179 - val_accuracy: 0.6103\n",
      "Epoch 358/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5607 - accuracy: 0.7975 - val_loss: 1.2791 - val_accuracy: 0.5956\n",
      "Epoch 359/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.7996 - val_loss: 1.2559 - val_accuracy: 0.6279\n",
      "Epoch 360/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5576 - accuracy: 0.7954 - val_loss: 1.2902 - val_accuracy: 0.6176\n",
      "Epoch 361/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5621 - accuracy: 0.7965 - val_loss: 1.1908 - val_accuracy: 0.6147\n",
      "Epoch 362/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5634 - accuracy: 0.7965 - val_loss: 1.2743 - val_accuracy: 0.6250\n",
      "Epoch 363/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5648 - accuracy: 0.7964 - val_loss: 1.2473 - val_accuracy: 0.6059\n",
      "Epoch 364/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.8024 - val_loss: 1.2441 - val_accuracy: 0.6206\n",
      "Epoch 365/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5675 - accuracy: 0.7942 - val_loss: 1.2218 - val_accuracy: 0.6368\n",
      "Epoch 366/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5748 - accuracy: 0.7899 - val_loss: 1.2904 - val_accuracy: 0.6221\n",
      "Epoch 367/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5631 - accuracy: 0.7945 - val_loss: 1.2950 - val_accuracy: 0.6147\n",
      "Epoch 368/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5646 - accuracy: 0.7959 - val_loss: 1.2665 - val_accuracy: 0.6000\n",
      "Epoch 369/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5576 - accuracy: 0.7975 - val_loss: 1.2926 - val_accuracy: 0.6088\n",
      "Epoch 370/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5567 - accuracy: 0.8002 - val_loss: 1.3010 - val_accuracy: 0.6176\n",
      "Epoch 371/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5559 - accuracy: 0.7963 - val_loss: 1.2792 - val_accuracy: 0.5956\n",
      "Epoch 372/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5656 - accuracy: 0.7941 - val_loss: 1.2474 - val_accuracy: 0.6176\n",
      "Epoch 373/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5642 - accuracy: 0.7983 - val_loss: 1.2045 - val_accuracy: 0.6265\n",
      "Epoch 374/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5534 - accuracy: 0.7976 - val_loss: 1.3192 - val_accuracy: 0.5985\n",
      "Epoch 375/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5482 - accuracy: 0.7999 - val_loss: 1.2606 - val_accuracy: 0.6059\n",
      "Epoch 376/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5573 - accuracy: 0.7962 - val_loss: 1.2666 - val_accuracy: 0.6294\n",
      "Epoch 377/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5584 - accuracy: 0.7971 - val_loss: 1.2447 - val_accuracy: 0.6265\n",
      "Epoch 378/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5611 - accuracy: 0.7979 - val_loss: 1.2944 - val_accuracy: 0.5985\n",
      "Epoch 379/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5484 - accuracy: 0.7993 - val_loss: 1.1794 - val_accuracy: 0.6294\n",
      "Epoch 380/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5535 - accuracy: 0.7984 - val_loss: 1.1779 - val_accuracy: 0.6221\n",
      "Epoch 381/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5497 - accuracy: 0.7986 - val_loss: 1.3734 - val_accuracy: 0.6103\n",
      "Epoch 382/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5538 - accuracy: 0.8010 - val_loss: 1.3168 - val_accuracy: 0.6103\n",
      "Epoch 383/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.7949 - val_loss: 1.2607 - val_accuracy: 0.6059\n",
      "Epoch 384/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5621 - accuracy: 0.7966 - val_loss: 1.2952 - val_accuracy: 0.6074\n",
      "Epoch 385/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5512 - accuracy: 0.7980 - val_loss: 1.3207 - val_accuracy: 0.6147\n",
      "Epoch 386/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5619 - accuracy: 0.7952 - val_loss: 1.3314 - val_accuracy: 0.6118\n",
      "Epoch 387/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5539 - accuracy: 0.7962 - val_loss: 1.2644 - val_accuracy: 0.6206\n",
      "Epoch 388/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5581 - accuracy: 0.7959 - val_loss: 1.2092 - val_accuracy: 0.6368\n",
      "Epoch 389/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5605 - accuracy: 0.7974 - val_loss: 1.2787 - val_accuracy: 0.6250\n",
      "Epoch 390/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5510 - accuracy: 0.7981 - val_loss: 1.3139 - val_accuracy: 0.6221\n",
      "Epoch 391/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5546 - accuracy: 0.7971 - val_loss: 1.4003 - val_accuracy: 0.5912\n",
      "Epoch 392/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5530 - accuracy: 0.7969 - val_loss: 1.2520 - val_accuracy: 0.6176\n",
      "Epoch 393/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5444 - accuracy: 0.8010 - val_loss: 1.3943 - val_accuracy: 0.6147\n",
      "Epoch 394/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5447 - accuracy: 0.8011 - val_loss: 1.2975 - val_accuracy: 0.6147\n",
      "Epoch 395/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5520 - accuracy: 0.7997 - val_loss: 1.3713 - val_accuracy: 0.6103\n",
      "Epoch 396/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.8014 - val_loss: 1.3202 - val_accuracy: 0.6265\n",
      "Epoch 397/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5466 - accuracy: 0.8011 - val_loss: 1.2928 - val_accuracy: 0.6162\n",
      "Epoch 398/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.8008 - val_loss: 1.3592 - val_accuracy: 0.6221\n",
      "Epoch 399/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.7991 - val_loss: 1.2548 - val_accuracy: 0.6162\n",
      "Epoch 400/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.8025 - val_loss: 1.2638 - val_accuracy: 0.6206\n",
      "Epoch 401/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5492 - accuracy: 0.7993 - val_loss: 1.3413 - val_accuracy: 0.6044\n",
      "Epoch 402/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.8039 - val_loss: 1.2665 - val_accuracy: 0.6324\n",
      "Epoch 403/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5587 - accuracy: 0.7984 - val_loss: 1.2910 - val_accuracy: 0.6088\n",
      "Epoch 404/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.8008 - val_loss: 1.3289 - val_accuracy: 0.6265\n",
      "Epoch 405/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.8038 - val_loss: 1.3085 - val_accuracy: 0.6191\n",
      "Epoch 406/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5417 - accuracy: 0.8008 - val_loss: 1.4617 - val_accuracy: 0.6059\n",
      "Epoch 407/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.8000 - val_loss: 1.3295 - val_accuracy: 0.6353\n",
      "Epoch 408/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5486 - accuracy: 0.7994 - val_loss: 1.3469 - val_accuracy: 0.6206\n",
      "Epoch 409/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5429 - accuracy: 0.8029 - val_loss: 1.3534 - val_accuracy: 0.6118\n",
      "Epoch 410/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5450 - accuracy: 0.8008 - val_loss: 1.3441 - val_accuracy: 0.6147\n",
      "Epoch 411/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5575 - accuracy: 0.7982 - val_loss: 1.2596 - val_accuracy: 0.6235\n",
      "Epoch 412/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5501 - accuracy: 0.8012 - val_loss: 1.3125 - val_accuracy: 0.6279\n",
      "Epoch 413/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5516 - accuracy: 0.8014 - val_loss: 1.4504 - val_accuracy: 0.6015\n",
      "Epoch 414/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5441 - accuracy: 0.8027 - val_loss: 1.3104 - val_accuracy: 0.6426\n",
      "Epoch 415/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.8047 - val_loss: 1.2856 - val_accuracy: 0.6279\n",
      "Epoch 416/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.8018 - val_loss: 1.3238 - val_accuracy: 0.6250\n",
      "Epoch 417/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5596 - accuracy: 0.7989 - val_loss: 1.3809 - val_accuracy: 0.6338\n",
      "Epoch 418/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5656 - accuracy: 0.7973 - val_loss: 1.3733 - val_accuracy: 0.6132\n",
      "Epoch 419/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5570 - accuracy: 0.7965 - val_loss: 1.3471 - val_accuracy: 0.6088\n",
      "Epoch 420/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5509 - accuracy: 0.7985 - val_loss: 1.3262 - val_accuracy: 0.6235\n",
      "Epoch 421/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5491 - accuracy: 0.7958 - val_loss: 1.3186 - val_accuracy: 0.6294\n",
      "Epoch 422/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5500 - accuracy: 0.7992 - val_loss: 1.3609 - val_accuracy: 0.6279\n",
      "Epoch 423/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5489 - accuracy: 0.8004 - val_loss: 1.3716 - val_accuracy: 0.5912\n",
      "Epoch 424/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5441 - accuracy: 0.8023 - val_loss: 1.2754 - val_accuracy: 0.5985\n",
      "Epoch 425/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5515 - accuracy: 0.7988 - val_loss: 1.2666 - val_accuracy: 0.6250\n",
      "Epoch 426/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.8025 - val_loss: 1.2333 - val_accuracy: 0.6279\n",
      "Epoch 427/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.8065 - val_loss: 1.2589 - val_accuracy: 0.6397\n",
      "Epoch 428/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.8064 - val_loss: 1.3472 - val_accuracy: 0.6074\n",
      "Epoch 429/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.8032 - val_loss: 1.3157 - val_accuracy: 0.6044\n",
      "Epoch 430/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5471 - accuracy: 0.8025 - val_loss: 1.2571 - val_accuracy: 0.6309\n",
      "Epoch 431/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.8009 - val_loss: 1.3621 - val_accuracy: 0.6132\n",
      "Epoch 432/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5465 - accuracy: 0.8020 - val_loss: 1.3298 - val_accuracy: 0.6074\n",
      "Epoch 433/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5374 - accuracy: 0.8042 - val_loss: 1.2753 - val_accuracy: 0.6176\n",
      "Epoch 434/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5311 - accuracy: 0.8067 - val_loss: 1.2681 - val_accuracy: 0.6235\n",
      "Epoch 435/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5819 - accuracy: 0.7916 - val_loss: 1.2622 - val_accuracy: 0.6147\n",
      "Epoch 436/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.8028 - val_loss: 1.3714 - val_accuracy: 0.6147\n",
      "Epoch 437/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5410 - accuracy: 0.7996 - val_loss: 1.3324 - val_accuracy: 0.6235\n",
      "Epoch 438/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5387 - accuracy: 0.8021 - val_loss: 1.2965 - val_accuracy: 0.6235\n",
      "Epoch 439/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5378 - accuracy: 0.8057 - val_loss: 1.3667 - val_accuracy: 0.6029\n",
      "Epoch 440/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.8090 - val_loss: 1.3694 - val_accuracy: 0.5765\n",
      "Epoch 441/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5543 - accuracy: 0.8004 - val_loss: 1.2961 - val_accuracy: 0.6221\n",
      "Epoch 442/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5498 - accuracy: 0.8017 - val_loss: 1.3020 - val_accuracy: 0.6118\n",
      "Epoch 443/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.8037 - val_loss: 1.3750 - val_accuracy: 0.6103\n",
      "Epoch 444/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.8046 - val_loss: 1.3454 - val_accuracy: 0.6074\n",
      "Epoch 445/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5461 - accuracy: 0.8045 - val_loss: 1.2880 - val_accuracy: 0.6279\n",
      "Epoch 446/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5360 - accuracy: 0.8076 - val_loss: 1.2469 - val_accuracy: 0.6118\n",
      "Epoch 447/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5388 - accuracy: 0.8045 - val_loss: 1.3230 - val_accuracy: 0.6132\n",
      "Epoch 448/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5470 - accuracy: 0.8054 - val_loss: 1.2662 - val_accuracy: 0.6147\n",
      "Epoch 449/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.8073 - val_loss: 1.2803 - val_accuracy: 0.6250\n",
      "Epoch 450/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5279 - accuracy: 0.8093 - val_loss: 1.2718 - val_accuracy: 0.6471\n",
      "Epoch 451/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5417 - accuracy: 0.8035 - val_loss: 1.4120 - val_accuracy: 0.6044\n",
      "Epoch 452/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.8019 - val_loss: 1.3289 - val_accuracy: 0.6294\n",
      "Epoch 453/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5482 - accuracy: 0.8020 - val_loss: 1.3059 - val_accuracy: 0.6147\n",
      "Epoch 454/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.8070 - val_loss: 1.3053 - val_accuracy: 0.6162\n",
      "Epoch 455/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5401 - accuracy: 0.8059 - val_loss: 1.3138 - val_accuracy: 0.6132\n",
      "Epoch 456/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.8003 - val_loss: 1.3322 - val_accuracy: 0.6118\n",
      "Epoch 457/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.7993 - val_loss: 1.3209 - val_accuracy: 0.6250\n",
      "Epoch 458/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5387 - accuracy: 0.8057 - val_loss: 1.2831 - val_accuracy: 0.6265\n",
      "Epoch 459/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5270 - accuracy: 0.8067 - val_loss: 1.2991 - val_accuracy: 0.6265\n",
      "Epoch 460/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5443 - accuracy: 0.8025 - val_loss: 1.3253 - val_accuracy: 0.6294\n",
      "Epoch 461/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.8058 - val_loss: 1.3015 - val_accuracy: 0.6294\n",
      "Epoch 462/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.8043 - val_loss: 1.3423 - val_accuracy: 0.6250\n",
      "Epoch 463/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5444 - accuracy: 0.8041 - val_loss: 1.3311 - val_accuracy: 0.6059\n",
      "Epoch 464/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.8053 - val_loss: 1.2255 - val_accuracy: 0.6206\n",
      "Epoch 465/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5367 - accuracy: 0.8033 - val_loss: 1.3750 - val_accuracy: 0.5765\n",
      "Epoch 466/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.8031 - val_loss: 1.2811 - val_accuracy: 0.6088\n",
      "Epoch 467/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5414 - accuracy: 0.8027 - val_loss: 1.3264 - val_accuracy: 0.6206\n",
      "Epoch 468/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5420 - accuracy: 0.8025 - val_loss: 1.2958 - val_accuracy: 0.6309\n",
      "Epoch 469/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.8108 - val_loss: 1.3005 - val_accuracy: 0.6309\n",
      "Epoch 470/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5357 - accuracy: 0.8058 - val_loss: 1.2852 - val_accuracy: 0.6221\n",
      "Epoch 471/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5315 - accuracy: 0.8046 - val_loss: 1.2833 - val_accuracy: 0.6176\n",
      "Epoch 472/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5284 - accuracy: 0.8063 - val_loss: 1.3255 - val_accuracy: 0.6206\n",
      "Epoch 473/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5240 - accuracy: 0.8120 - val_loss: 1.3257 - val_accuracy: 0.6294\n",
      "Epoch 474/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5296 - accuracy: 0.8088 - val_loss: 1.3189 - val_accuracy: 0.6147\n",
      "Epoch 475/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.8093 - val_loss: 1.2945 - val_accuracy: 0.6206\n",
      "Epoch 476/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.8049 - val_loss: 1.2967 - val_accuracy: 0.6029\n",
      "Epoch 477/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5356 - accuracy: 0.8094 - val_loss: 1.2459 - val_accuracy: 0.6235\n",
      "Epoch 478/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.8068 - val_loss: 1.3951 - val_accuracy: 0.5985\n",
      "Epoch 479/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5338 - accuracy: 0.8062 - val_loss: 1.3929 - val_accuracy: 0.6044\n",
      "Epoch 480/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.8068 - val_loss: 1.3300 - val_accuracy: 0.6221\n",
      "Epoch 481/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5284 - accuracy: 0.8094 - val_loss: 1.3790 - val_accuracy: 0.6279\n",
      "Epoch 482/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5479 - accuracy: 0.8031 - val_loss: 1.2619 - val_accuracy: 0.6265\n",
      "Epoch 483/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5438 - accuracy: 0.8013 - val_loss: 1.3834 - val_accuracy: 0.5882\n",
      "Epoch 484/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5277 - accuracy: 0.8075 - val_loss: 1.4150 - val_accuracy: 0.6118\n",
      "Epoch 485/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5372 - accuracy: 0.8024 - val_loss: 1.3701 - val_accuracy: 0.6265\n",
      "Epoch 486/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5297 - accuracy: 0.8109 - val_loss: 1.4007 - val_accuracy: 0.6118\n",
      "Epoch 487/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5257 - accuracy: 0.8103 - val_loss: 1.3284 - val_accuracy: 0.6029\n",
      "Epoch 488/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.8071 - val_loss: 1.3179 - val_accuracy: 0.6250\n",
      "Epoch 489/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.8075 - val_loss: 1.3419 - val_accuracy: 0.6368\n",
      "Epoch 490/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.8068 - val_loss: 1.2890 - val_accuracy: 0.6338\n",
      "Epoch 491/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5308 - accuracy: 0.8067 - val_loss: 1.3245 - val_accuracy: 0.6250\n",
      "Epoch 492/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.8093 - val_loss: 1.3875 - val_accuracy: 0.6294\n",
      "Epoch 493/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.8039 - val_loss: 1.4227 - val_accuracy: 0.6118\n",
      "Epoch 494/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5385 - accuracy: 0.8074 - val_loss: 1.3637 - val_accuracy: 0.6191\n",
      "Epoch 495/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.8050 - val_loss: 1.4150 - val_accuracy: 0.6147\n",
      "Epoch 496/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5232 - accuracy: 0.8088 - val_loss: 1.3820 - val_accuracy: 0.6029\n",
      "Epoch 497/500\n",
      "195/195 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.8088 - val_loss: 1.4516 - val_accuracy: 0.6162\n",
      "Epoch 498/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5290 - accuracy: 0.8076 - val_loss: 1.3136 - val_accuracy: 0.6235\n",
      "Epoch 499/500\n",
      "195/195 [==============================] - 1s 6ms/step - loss: 0.5303 - accuracy: 0.8063 - val_loss: 1.3035 - val_accuracy: 0.6074\n",
      "Epoch 500/500\n",
      "195/195 [==============================] - 1s 7ms/step - loss: 0.5307 - accuracy: 0.8097 - val_loss: 1.3639 - val_accuracy: 0.6103\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(X_train_cnn, y_train_e_cnn, batch_size=128, epochs=500, validation_data=(X_test_cnn, y_test_e_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6YPJb3WmVp1z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6YPJb3WmVp1z",
    "outputId": "49b80ba9-efcc-45c3-c591-29d257181e5f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5JElEQVR4nO3dd3hTZfsH8G86ku49aQstFMouUyggQ5aACE7kVQEVJ6iI6Ctu8X3FV3+4Edy4EGUrQ9lT9pJZVqGldNK92+T8/nia5GQ0HaQ9bfl+rqtXk5OTkydByc393M/9qCRJkkBERETUTDgoPQAiIiIie2JwQ0RERM0KgxsiIiJqVhjcEBERUbPC4IaIiIiaFQY3RERE1KwwuCEiIqJmhcENERERNSsMboiIiKhZYXBDRI3epUuXoFKpsGjRolo/d9u2bVCpVNi2bZvN8xYtWgSVSoVLly7VaYxE1HgwuCEiIqJmhcENERERNSsMboiIiKhZYXBDRNV68803oVKpcPbsWTzwwAPw9vZGYGAgXnvtNUiShKSkJIwbNw5eXl4ICQnBvHnzLK6Rnp6ORx55BMHBwXBxcUFsbCy+//57i/NycnIwZcoUeHt7w8fHB5MnT0ZOTo7VcZ05cwZ33303/Pz84OLigl69euH333+363v//PPP0alTJ2g0GrRo0QLTpk2zGM+5c+dw1113ISQkBC4uLggPD8d9992H3NxcwzkbN27EgAED4OPjAw8PD8TExODll1+261iJSHBSegBE1HRMmDABHTp0wLvvvou1a9fiP//5D/z8/PDFF1/glltuwf/+9z/8/PPPmDVrFnr37o2BAwcCAIqLizF48GCcP38e06dPR1RUFJYuXYopU6YgJycHzz77LABAkiSMGzcOu3btwhNPPIEOHTpg5cqVmDx5ssVYTp48if79+yMsLAwvvfQS3N3d8dtvv2H8+PFYvnw57rjjjut+v2+++SbeeustDBs2DE8++STi4+OxYMECHDhwALt374azszPKysowcuRIlJaW4umnn0ZISAiSk5OxZs0a5OTkwNvbGydPnsRtt92Grl27Ys6cOdBoNDh//jx279593WMkIiskIqJqvPHGGxIA6bHHHjMcq6iokMLDwyWVSiW9++67huPZ2dmSq6urNHnyZMOxjz76SAIg/fTTT4ZjZWVlUlxcnOTh4SHl5eVJkiRJq1atkgBI7733nsnr3HzzzRIA6bvvvjMcHzp0qNSlSxeppKTEcEyn00n9+vWT2rZtazi2detWCYC0detWm+/xu+++kwBICQkJkiRJUnp6uqRWq6URI0ZIWq3WcN5nn30mAZC+/fZbSZIk6ciRIxIAaenSpVVe+8MPP5QASBkZGTbHQET2wWkpIqqxqVOnGm47OjqiV69ekCQJjzzyiOG4j48PYmJicPHiRcOxdevWISQkBBMnTjQcc3Z2xjPPPIOCggJs377dcJ6TkxOefPJJk9d5+umnTcaRlZWFLVu24N5770V+fj4yMzORmZmJa9euYeTIkTh37hySk5Ov671u2rQJZWVlmDFjBhwcjH9VPvroo/Dy8sLatWsBAN7e3gCAv/76C0VFRVav5ePjAwBYvXo1dDrddY2LiKrH4IaIaqxly5Ym9729veHi4oKAgACL49nZ2Yb7ly9fRtu2bU2CBADo0KGD4XH979DQUHh4eJicFxMTY3L//PnzkCQJr732GgIDA01+3njjDQCixud66Mdk/tpqtRqtW7c2PB4VFYWZM2fi66+/RkBAAEaOHIn58+eb1NtMmDAB/fv3x9SpUxEcHIz77rsPv/32GwMdonrCmhsiqjFHR8caHQNE/Ux90QcFs2bNwsiRI62eEx0dXW+vb27evHmYMmUKVq9ejQ0bNuCZZ57B3LlzsXfvXoSHh8PV1RU7duzA1q1bsXbtWvz555/49ddfccstt2DDhg1VfoZEVDfM3BBRvWvVqhXOnTtnkak4c+aM4XH975SUFBQUFJicFx8fb3K/devWAMTU1rBhw6z+eHp6XveYrb12WVkZEhISDI/rdenSBa+++ip27NiBnTt3Ijk5GQsXLjQ87uDggKFDh+KDDz7AqVOn8N///hdbtmzB1q1br2ucRGSJwQ0R1bvRo0cjNTUVv/76q+FYRUUFPv30U3h4eGDQoEGG8yoqKrBgwQLDeVqtFp9++qnJ9YKCgjB48GB88cUXSElJsXi9jIyM6x7zsGHDoFar8cknn5hkob755hvk5uZizJgxAIC8vDxUVFSYPLdLly5wcHBAaWkpAFEjZK5bt24AYDiHiOyH01JEVO8ee+wxfPHFF5gyZQoOHTqEyMhILFu2DLt378ZHH31kyLKMHTsW/fv3x0svvYRLly6hY8eOWLFihUn9it78+fMxYMAAdOnSBY8++ihat26NtLQ07NmzB1euXMGxY8eua8yBgYGYPXs23nrrLdx66624/fbbER8fj88//xy9e/fGAw88AADYsmULpk+fjnvuuQft2rVDRUUFfvzxRzg6OuKuu+4CAMyZMwc7duzAmDFj0KpVK6Snp+Pzzz9HeHg4BgwYcF3jJCJLDG6IqN65urpi27ZteOmll/D9998jLy8PMTEx+O677zBlyhTDeQ4ODvj9998xY8YM/PTTT1CpVLj99tsxb948dO/e3eSaHTt2xMGDB/HWW29h0aJFuHbtGoKCgtC9e3e8/vrrdhn3m2++icDAQHz22Wd47rnn4Ofnh8ceewzvvPMOnJ2dAQCxsbEYOXIk/vjjDyQnJ8PNzQ2xsbFYv349+vbtCwC4/fbbcenSJXz77bfIzMxEQEAABg0ahLfeesuw2oqI7Ecl1WfVHxEREVEDY80NERERNSsMboiIiKhZYXBDREREzQqDGyIiImpWGNwQERFRs8LghoiIiJqVG67PjU6nw9WrV+Hp6QmVSqX0cIiIiKgGJElCfn4+WrRoYbEJr7kbLri5evUqIiIilB4GERER1UFSUhLCw8NtnnPDBTf6Nu9JSUnw8vJSeDRERERUE3l5eYiIiKjRprg3XHCjn4ry8vJicENERNTE1KSkhAXFRERE1KwwuCEiIqJmhcENERERNSs3XM1NTWm1WpSXlys9jCbJ2dkZjo6OSg+DiIhuUAxuzEiShNTUVOTk5Cg9lCbNx8cHISEh7CVEREQNjsGNGX1gExQUBDc3N34515IkSSgqKkJ6ejoAIDQ0VOERERHRjYbBjYxWqzUENv7+/koPp8lydXUFAKSnpyMoKIhTVERE1KBYUCyjr7Fxc3NTeCRNn/4zZN0SERE1NAY3VnAq6vrxMyQiIqUoGtwsWLAAXbt2NXQLjouLw/r1620+Z+nSpWjfvj1cXFzQpUsXrFu3roFGS0RERE2BosFNeHg43n33XRw6dAgHDx7ELbfcgnHjxuHkyZNWz//7778xceJEPPLIIzhy5AjGjx+P8ePH48SJEw088uYtMjISH330kdLDICIiqhOVJEmS0oOQ8/Pzw/vvv49HHnnE4rEJEyagsLAQa9asMRzr27cvunXrhoULF9bo+nl5efD29kZubq7F3lIlJSVISEhAVFQUXFxcru+NNLDBgwejW7dudglKMjIy4O7ufl21R035syQiosbH1ve3uUZTc6PVarFkyRIUFhYiLi7O6jl79uzBsGHDTI6NHDkSe/bsqfK6paWlyMvLM/mpDzpJQlmFFmUVunq5/vWSJAkVFRU1OjcwMJBF1URE1GQpHtwcP34cHh4e0Gg0eOKJJ7By5Up07NjR6rmpqakIDg42ORYcHIzU1NQqrz937lx4e3sbfiIiIuw6fr3iMi3OpObjYmZBvVzflilTpmD79u34+OOPoVKpoFKpsGjRIqhUKqxfvx49e/aERqPBrl27cOHCBYwbNw7BwcHw8PBA7969sWnTJpPrmU9LqVQqfP3117jjjjvg5uaGtm3b4vfff2/gd0lERFQzigc3MTExOHr0KPbt24cnn3wSkydPxqlTp+x2/dmzZyM3N9fwk5SUVKvnS5KEorKKGv2UlGtRUq6t8fnV/dR0xvDjjz9GXFwcHn30UaSkpCAlJcUQxL300kt49913cfr0aXTt2hUFBQUYPXo0Nm/ejCNHjuDWW2/F2LFjkZiYaPM13nrrLdx77734559/MHr0aNx///3Iysqq1WdJRETUEBRv4qdWqxEdHQ0A6NmzJw4cOICPP/4YX3zxhcW5ISEhSEtLMzmWlpaGkJCQKq+v0Wig0WjqPL7ici06vv5XnZ9/PU7NGQk3dfV/RN7e3lCr1XBzczN8FmfOnAEAzJkzB8OHDzec6+fnh9jYWMP9t99+GytXrsTvv/+O6dOnV/kaU6ZMwcSJEwEA77zzDj755BPs378ft956a53eGxERUX1RPHNjTqfTobS01OpjcXFx2Lx5s8mxjRs3VlmjQ0CvXr1M7hcUFGDWrFno0KEDfHx84OHhgdOnT1ebuenatavhtru7O7y8vAxbLBARETUmimZuZs+ejVGjRqFly5bIz8/H4sWLsW3bNvz1l8iUTJo0CWFhYZg7dy4A4Nlnn8WgQYMwb948jBkzBkuWLMHBgwfx5Zdf1tsYXZ0dcWrOyGrPKyqrwMWMQqgdHdAuxNNur3293N3dTe7PmjULGzduxP/93/8hOjoarq6uuPvuu1FWVmbzOs7Ozib3VSoVdLrGWTxNREQ3NkWDm/T0dEyaNAkpKSnw9vZG165d8ddffxmmURITE+HgYEwu9evXD4sXL8arr76Kl19+GW3btsWqVavQuXPnehujSqWq0dQQALg4O8LZ0aHG59uTWq2GVqut9rzdu3djypQpuOOOOwCITM6lS5fqeXREREQNR9Hg5ptvvrH5+LZt2yyO3XPPPbjnnnvqaURNV2RkJPbt24dLly7Bw8OjyqxK27ZtsWLFCowdOxYqlQqvvfYaMzBERNSsNLqam6ZK6Z2UZs2aBUdHR3Ts2BGBgYFV1tB88MEH8PX1Rb9+/TB27FiMHDkSPXr0aODREhER1Z9G16G4vtVXh+LisgqcSy+As6MDOoTa7px4I2CHYiIisqcm2aGYiIiIyB4Y3NiNmJi6odJgREREjRCDG3tjdENERKQoBjdERETUrDC4sRell0sRERERAAY3dsPYhoiIqHFgcGN3LLohIiJSEoMbO2NoQ0REpCwGN0RERNSsMLghIiKiZoXBTTMxePBgzJgxw27XmzJlCsaPH2+36xERETUUBjd2YlgtxaIbIiIiRTG4aQamTJmC7du34+OPP4ZKpYJKpcKlS5dw4sQJjBo1Ch4eHggODsaDDz6IzMxMw/OWLVuGLl26wNXVFf7+/hg2bBgKCwvx5ptv4vvvv8fq1asN19u2bZtyb5CIiKgWnJQeQKMnSUB5UfXnlWuhKi8CVCqgzE4fq7ObuF41Pv74Y5w9exadO3fGnDlzxFOdnXHTTTdh6tSp+PDDD1FcXIx///vfuPfee7FlyxakpKRg4sSJeO+993DHHXcgPz8fO3fuhCRJmDVrFk6fPo28vDx89913AAA/Pz/7vCciIqJ6xuCmOuVFwDstqj1NA6CLvV/75auA2r3a07y9vaFWq+Hm5oaQkBAAwH/+8x90794d77zzjuG8b7/9FhERETh79iwKCgpQUVGBO++8E61atQIAdOlifAeurq4oLS01XI+IiKipYHDTTB07dgxbt26Fh4eHxWMXLlzAiBEjMHToUHTp0gUjR47EiBEjcPfdd8PX11eB0RIREdkPg5vqOLuJDEo1yiq0iE8rgINKhU4tvOz32nVUUFCAsWPH4n//+5/FY6GhoXB0dMTGjRvx999/Y8OGDfj000/xyiuvYN++fYiKirqeURMRESmKwU11VKoaTQ3BQQvJWQeppufbmVqthlarNdzv0aMHli9fjsjISDg5Wf9jVqlU6N+/P/r374/XX38drVq1wsqVKzFz5kyL6xERETUVXC3VTERGRmLfvn24dOkSMjMzMW3aNGRlZWHixIk4cOAALly4gL/++gsPPfQQtFot9u3bh3feeQcHDx5EYmIiVqxYgYyMDHTo0MFwvX/++Qfx8fHIzMxEeXm5wu+QiIioZhjc2I1Y1aRUm5tZs2bB0dERHTt2RGBgIMrKyrB7925otVqMGDECXbp0wYwZM+Dj4wMHBwd4eXlhx44dGD16NNq1a4dXX30V8+bNw6hRowAAjz76KGJiYtCrVy8EBgZi9+7dCr0zIiKi2lFJknRDtZ3Ly8uDt7c3cnNz4eVlWhtTUlKChIQEREVFwcXFpVbXLavQ4UxqHlQqFbqEedtzyE3S9XyWRERE5mx9f5tj5oaIiIiaFQY3dsLtF4iIiBoHBjf2Un0jYSIiImoADG7sjqkbIiIiJTG4seJ6aqwZ2gg3WJ06ERE1IgxuZJydnQEARUU12CiTbNJ/hvrPlIiIqKGwQ7GMo6MjfHx8kJ6eDgBwc3ODqga7cgNAuVYHqaIMgFgGfaOSJAlFRUVIT0+Hj48PHB0dlR4SERHdYBjcmNHvgq0PcGpKq5OQniuCGnWxq93H1dT4+PhwR3EiIlIEgxszKpUKoaGhCAoKqtWWAzlFZXh81d8AgI3PDYKDw427fMrZ2ZkZGyIiUgyDmyo4OjrW6gtao3VAcr7YaFLj4gLHGzi4ISIiUhILiu1EXprDlUJERETKYXBjJypZFz+GNkRERMphcGMvJpkb5YZBRER0o2NwYycm01LM3RARESmGwY2dyMuHmbkhIiJSDoMbO6lpsz8iIiKqXwxu7ISZGyIiosaBwY2dsOaGiIiocWBwYycmS8EZ2xARESmGwY2dmGZuiIiISCkMbuoBOxQTEREph8GNnTBzQ0RE1DgwuLET1twQERE1Dgxu7MSkzQ2DGyIiIsUwuLET09iG0Q0REZFSGNzYibxDMaeliIiIlMPgxk44K0VERNQ4MLixE5PVUkzdEBERKYbBjZ2YTEspOA4iIqIbHYObesDEDRERkXIY3NiRPnnD1VJERETKYXBjR4aJKcY2REREimFwY0f6uhvGNkRERMphcGNH+swNa26IiIiUo2hwM3fuXPTu3Ruenp4ICgrC+PHjER8fb/M5ixYtgkqlMvlxcXFpoBHbxpobIiIi5Ska3Gzfvh3Tpk3D3r17sXHjRpSXl2PEiBEoLCy0+TwvLy+kpKQYfi5fvtxAI7ZNv3kmMzdERETKcVLyxf/880+T+4sWLUJQUBAOHTqEgQMHVvk8lUqFkJCQ+h5e7RkyN0RERKSURlVzk5ubCwDw8/OzeV5BQQFatWqFiIgIjBs3DidPnqzy3NLSUuTl5Zn81BdjzQ3DGyIiIqU0muBGp9NhxowZ6N+/Pzp37lzleTExMfj222+xevVq/PTTT9DpdOjXrx+uXLli9fy5c+fC29vb8BMREVFfb8FYc8PYhoiISDEqqZGkGZ588kmsX78eu3btQnh4eI2fV15ejg4dOmDixIl4++23LR4vLS1FaWmp4X5eXh4iIiKQm5sLLy8vu4xdr8Nrf6K4XIudLw5BhJ+bXa9NRER0I8vLy4O3t3eNvr8VrbnRmz59OtasWYMdO3bUKrABAGdnZ3Tv3h3nz5+3+rhGo4FGo7HHMKvFzA0REZHyFJ2WkiQJ06dPx8qVK7FlyxZERUXV+hparRbHjx9HaGhoPYywdgw1NywpJiIiUoyimZtp06Zh8eLFWL16NTw9PZGamgoA8Pb2hqurKwBg0qRJCAsLw9y5cwEAc+bMQd++fREdHY2cnBy8//77uHz5MqZOnarY+9AzdChmbENERKQYRYObBQsWAAAGDx5scvy7777DlClTAACJiYlwcDAmmLKzs/Hoo48iNTUVvr6+6NmzJ/7++2907NixoYZdJWPmhoiIiJSiaHBTk1rmbdu2mdz/8MMP8eGHH9bTiK6ToeaG4Q0REZFSGs1S8OaAmRsiIiLlMbixI9bcEBERKY/BjR3pl4Izd0NERKQcBjd2ZNx+QdFhEBER3dAY3NiRYVpK4XEQERHdyBjc2BEzN0RERMpjcGNHhu0XmLshIiJSDIMbu+JqKSIiIqUxuLEjbpxJRESkPAY3dsSNM4mIiJTH4MaOmLkhIiJSHoMbO1IZcjdERESkFAY3dsTMDRERkfIY3NgRa26IiIiUx+DGjrhxJhERkfIY3NQDxjZERETKYXBjR8aaG4Y3RERESmFwY0fG7ReIiIhIKQxu7EjF7ReIiIgUx+DGjlSGNjeMboiIiJTC4MaODEvBGdsQEREphsGNHRmWgis8DiIiohsZgxs7YuaGiIhIeQxu7IlLwYmIiBTH4MaOjNsvEBERkVIY3NgRt18gIiJSHoMbO+LGmURERMpjcGNHKs5LERERKY7BjR0ZOhQrPA4iIqIbGYMbOzJunKnsOIiIiG5kDG7qAWtuiIiIlMPgxo64WoqIiEh5DG7siPXEREREymNwY0cqdigmIiJSHIMbOzIEN8oOg4iI6IbG4MaOVGB0Q0REpDQGN3ZkzNwwuiEiIlIKg5t6wJIbIiIi5TC4sSPDaikGN0RERIphcGNPKm6/QEREpDQGN3ZkzNwwvCEiIlIKgxs74lJwIiIi5TG4sSPW3BARESmPwY0d6feWYu6GiIhIOQxu7IiZGyIiIuUxuLEj1twQEREpj8GNHem3X2DmhoiISDkMbuyJ2y8QEREpjsGNHbHmhoiISHkMbuyINTdERETKY3BjR8aaG4Y3RERESmFwY0eGNjdERESkGAY3dmSYlmLihoiISDEMbuzIMC3FqhsiIiLFMLixI2ZuiIiIlMfgph4wuCEiIlIOgxs70m+cydiGiIhIOYoGN3PnzkXv3r3h6emJoKAgjB8/HvHx8dU+b+nSpWjfvj1cXFzQpUsXrFu3rgFGWz1jEz+GN0REREpRNLjZvn07pk2bhr1792Ljxo0oLy/HiBEjUFhYWOVz/v77b0ycOBGPPPIIjhw5gvHjx2P8+PE4ceJEA47cOjbxIyIiUp5KakRphoyMDAQFBWH79u0YOHCg1XMmTJiAwsJCrFmzxnCsb9++6NatGxYuXFjta+Tl5cHb2xu5ubnw8vKy29gB4KHv9mNrfAbeu6sr7u0dYddrExER3chq8/3dqGpucnNzAQB+fn5VnrNnzx4MGzbM5NjIkSOxZ88eq+eXlpYiLy/P5Ke+GGtuGk28SEREdMNpNMGNTqfDjBkz0L9/f3Tu3LnK81JTUxEcHGxyLDg4GKmpqVbPnzt3Lry9vQ0/ERH1l1HhxplERETKazTBzbRp03DixAksWbLErtedPXs2cnNzDT9JSUl2vb4ca26IiIiU56T0AABg+vTpWLNmDXbs2IHw8HCb54aEhCAtLc3kWFpaGkJCQqyer9FooNFo7DZW2/QbZzbQyxEREZEFRTM3kiRh+vTpWLlyJbZs2YKoqKhqnxMXF4fNmzebHNu4cSPi4uLqa5g1ZszcMLohIiJSiqKZm2nTpmHx4sVYvXo1PD09DXUz3t7ecHV1BQBMmjQJYWFhmDt3LgDg2WefxaBBgzBv3jyMGTMGS5YswcGDB/Hll18q9j70WHNDRESkPEUzNwsWLEBubi4GDx6M0NBQw8+vv/5qOCcxMREpKSmG+/369cPixYvx5ZdfIjY2FsuWLcOqVatsFiE3FNbcEBERKU/RzE1NWuxs27bN4tg999yDe+65px5GdH30u4IzdUNERKScRrNaqjlg5oaIiEh5DG7sSMXEDRERkeIY3NiRyrAUnNENERGRUhjc2BOnpYiIiBTH4MaOuBSciIhIeQxu7Mi4cSYREREphcGNHRkzNwxviIiIlMLgxo70q6WIiIhIOQxu7Ig1N0RERMpjcGNHxpobRjdERERKYXBjR8zcEBERKY/BjT2xzw0REZHiGNzYkbFDscIDISIiuoExuLEj48aZjG6IiIiUwuDGjlhzQ0REpDwGN3bEPjdERETKq1Nw8/3332Pt2rWG+y+++CJ8fHzQr18/XL582W6Da2q4KzgREZHy6hTcvPPOO3B1dQUA7NmzB/Pnz8d7772HgIAAPPfcc3YdYFNiqLlhbENERKQYp7o8KSkpCdHR0QCAVatW4a677sJjjz2G/v37Y/DgwfYcX5Oi4lJwIiIixdUpc+Ph4YFr164BADZs2IDhw4cDAFxcXFBcXGy/0TU5XApORESktDplboYPH46pU6eie/fuOHv2LEaPHg0AOHnyJCIjI+05viaFS8GJiIiUV6fMzfz58xEXF4eMjAwsX74c/v7+AIBDhw5h4sSJdh1gU8Kl4ERERMqrU+bGx8cHn332mcXxt95667oH1JSx5oaIiEh5dcrc/Pnnn9i1a5fh/vz589GtWzf861//QnZ2tt0G19SowOVSRERESqtTcPPCCy8gLy8PAHD8+HE8//zzGD16NBISEjBz5ky7DrApYeaGiIhIeXWalkpISEDHjh0BAMuXL8dtt92Gd955B4cPHzYUF9+IWHNDRESkvDplbtRqNYqKigAAmzZtwogRIwAAfn5+hozOjUhVmbrhaikiIiLl1ClzM2DAAMycORP9+/fH/v378euvvwIAzp49i/DwcLsOsCli5oaIiEg5dcrcfPbZZ3BycsKyZcuwYMEChIWFAQDWr1+PW2+91a4DbEpYc0NERKS8OmVuWrZsiTVr1lgc//DDD697QE2Zih2KiYiIFFen4AYAtFotVq1ahdOnTwMAOnXqhNtvvx2Ojo52G1xTww7FREREyqtTcHP+/HmMHj0aycnJiImJAQDMnTsXERERWLt2Ldq0aWPXQTYV+tVSjG2IiIiUU6eam2eeeQZt2rRBUlISDh8+jMOHDyMxMRFRUVF45pln7D3GJoM1N0RERMqrU+Zm+/bt2Lt3L/z8/AzH/P398e6776J///52G1xTY1gKzqIbIiIixdQpc6PRaJCfn29xvKCgAGq1+roH1VSxiR8REZHy6hTc3HbbbXjsscewb98+SJIESZKwd+9ePPHEE7j99tvtPcamg9NSREREiqtTcPPJJ5+gTZs2iIuLg4uLC1xcXNCvXz9ER0fjo48+svMQmw4uBSciIlJenWpufHx8sHr1apw/f96wFLxDhw6Ijo626+CaGi4FJyIiUl6Ng5vqdvveunWr4fYHH3xQ9xE1Yay5ISIiUl6Ng5sjR47U6Dz9iqEb0Q381omIiBqNGgc38swMWWesuWHqhoiISCl1Kigm69jEj4iISHkMbuyINTdERETKY3BjT/oOxczdEBERKYbBjR0xc0NERKQ8Bjd2xJobIiIi5TG4sSN2KCYiIlIegxs7Mva5YXRDRESkFAY3dsSaGyIiIuUxuLEjQ80NgxsiIiLFMLixIxWXghMRESmOwU09YOaGiIhIOQxu7IhLwYmIiJTH4MaOuBSciIhIeQxu7MiYuWF0Q0REpBQGN3bENjdERETKUzS42bFjB8aOHYsWLVpApVJh1apVNs/ftm0bVCqVxU9qamrDDLgarLkhIiJSnqLBTWFhIWJjYzF//vxaPS8+Ph4pKSmGn6CgoHoaYe0Ya24Y3hARESnFSckXHzVqFEaNGlXr5wUFBcHHx8f+A7pOzNwQEREpr0nW3HTr1g2hoaEYPnw4du/erfRwLDBxQ0REpBxFMze1FRoaioULF6JXr14oLS3F119/jcGDB2Pfvn3o0aOH1eeUlpaitLTUcD8vL6/exmfsUExERERKaVLBTUxMDGJiYgz3+/XrhwsXLuDDDz/Ejz/+aPU5c+fOxVtvvdUg4zNunMnwhoiISClNclpK7qabbsL58+erfHz27NnIzc01/CQlJdXbWFhzQ0REpLwmlbmx5ujRowgNDa3ycY1GA41G0yBjYZ8bIiIi5Ska3BQUFJhkXRISEnD06FH4+fmhZcuWmD17NpKTk/HDDz8AAD766CNERUWhU6dOKCkpwddff40tW7Zgw4YNSr0FE9wVnIioidFpAQdHpUdBdqZocHPw4EEMGTLEcH/mzJkAgMmTJ2PRokVISUlBYmKi4fGysjI8//zzSE5OhpubG7p27YpNmzaZXENJhmkpxjZERI1fQQbweV+g4zjgtg+UHg3ZkUq6wapf8/Ly4O3tjdzcXHh5edn12j/uuYTXVp/ErZ1CsPDBnna9NhER2dm2d4Ftc8XtN3NNH7v8N5CbDHS9p+HH1RTt+xLQlgL9nq63l6jN93eTr7lpVDgtRUTUPHxX2WA2qD0Q0kXZsTR2pQXA+hfE7dh/Ae7+yo4HzWC1VGOiqv4UIiJqNGrwt3b25fofRlNXmG68XV6o3DhkGNzYEWtuiIiaEJXsK1BbYbxdUdbwY2nK8tOMt8sY3DRbjG2IiJoAlSxzU1Zg/TZZl7QfWDoFyEkCChpfcMOaGzsy7gqu8ECIiKh6Olm2pqwAcPUx3tarKGnQIVmoKANSjwMtujXskvWEHcCZdcDwtwAnK73ivhkufp9cBZN/0jeSwJCZGztSsYsfEVHTIc8yVHlb4S/r9S8AX98CbH+vYV/3+7HAvgXAvoXVnGj2fVfK4KbZMe4tpegwiIhuPGf/AtbMBCpKqz9Xr7zIeFv+pVxVoKOEQ4vE7+3vNtxrluYbb298HVj3gukXW1FW1c9V+vOqxODGjri3FBGRQhbfCxz8BvhPEPDbpJr9K7NMFtyUyb7Q5V/ujeTLut6UFwNfDAQ+6w2c/kMcu3rU9Jz9XwIZ8cb7qf9UfT3556ggBjd2ZKy5YXhDRKSYU6tNv4yrIl+2XGXmpvK4TmufsTU2aSeBlGNA5lnR1BAAkg9Znlcsy9akHq/6eo0kGGRwY0/M3BAR1Q+drurHrP2DUj7lVBWTzI2NaamsBOB/kcCyR+onyCktADLO2u96RVk1788jf69pJ4Af7wD2f2V5nnxF1LULNbueghjc2BFrboiI6sGa54B57cReUNaUWpkKWfYQcPBb29c1qbmRT0XJp6gKgEs7gdI84MQyYOc842N/fwqsfKJmAY8kAb8/A+z+RNxP+Qc48A1QnAP8ej8wvzdw5WD116mJ96OBj7sC+anVn2seBF7YAuRdsTxP/tnnp1R9PRYUNz/GXcGJiMhuLmwBCjOAK/utP15spcA1+5IIioCqswlVrYoyP56bbLx/fJn4nbAT2PAqcOwXyxoVAMhJBPYuEDUtAJB5Djj8PbD5LbHE+oubgbUzgT3zgYvbxDl75lsfZ21JlcFWTYKlmmZa5JmbvKumj7UeAgx5Rdy+tEPU8Pwxo2bXrScMbuzImLlheENEZDf6FVC5VjIKAFB0rernHv0FeCfM+lSLPGtRnA0k7hNZGPNpKXkmIzNedOTd9q7pc80tuR/48yXgr5fF/ZIc8VtXARxbbDwvSzbFk51geR0nV9lYajDVpi2X3a7ByjFbwc2YeUBEX3FbvsWCPnPj7CZ+95wCqN3FbXkNj4IY3NiRiptLEVFzlZ8G7PoIKLQRSNQXffYjN8n647aWJq96AoAErJtl+Zj8i333x8C3I4BVT1oWF5sHVZd2mhbV6oObijLg8A+i3kW/okg/NVYi23U8YYfxtjwIyEqwXddgK4iz9p7kgU5NzjcX1hPoNlHcLqgMbirKRBYNAJ7YBTz0J9BxHKD2EMekytoorxbVv3Y9YnBjR9xbiojqXXkJsHchkHWxYV936WRg0xvAyscb9nUBY5fgnDoEN3IXtgJrnzdmQKx9sf/zK3BqlfG+PLgJ6Wo8p1QWrOiDmyM/AL8/DSwcYHldeXAjv516QnY8R0xn6em0QEWx8X5RZlXvTLy3H+8AUo7Kxl6D+hdbG11qvACPYHE7Jwn441nR2A8AHJwB3yigVZz48tNnbvQUDm64/YIdGZaCs+qGiOrLznnAjveALf8BXq5imsZeyopE5qP9WCBxjzh2fmP9vqY5STIGN/IMSvIhwK814Opbs4wGAPw4Xvz2CAYGvVj1iqo8WY1NWb4xa9F7KvDHM8C5Dabn66ecEveK36V5gIuP8XhxtmlAY8Ls+yL7EuDbqvK1zQIP/fu8tAtwVAMRNxkfWzcLuHZe1CcZzrcyXWbO1lSXxhNwDxK300+KHz3PUMBBlh/RZ270vMKqf+16xMyNHTFzQ0T1Tv/lZc9maWWF4rrmu2En7BA9Y3Z/ZL/Xqi15x2F9cLPvC+CrW4xFqzUNbvQyzgDfjQG0Zu+371OW5+YkGoOrLneLYMqcPnPjGWI8pg9sAFFwXJpXs7HlXgEKM8X7Ng9uCjNFBuWHcWJvp4yz4ryD34rAxty2d4ATK2TXTgY2zxEBcknleGxNS2k8AY8g6495hZqdy+Cm2WNwQ3SDyE+zvgy5OuXFQPppZf+yKC8G1s4S0xmrnhJTGtvmmp6jLyItzqnZNYuygH1f1q0uR5JENkq/GklPPi1TkCqyKOtfFPf100fWVkvZknkOuLzLeN8rDBj5DuAdXvVzPILF1Ev7MZaP6YObqv5byLpgI3Nj5soB4P02IngxDzySDwHHlxo3/Nz4GrD1v8ZVYeYknVgSX14ZnG1/VwQ2m+cAP90lAiP9tFT3BwBPs6kkJxcRsLn5W17b0yy4aWTTUgxu7Mi4FJzRDVGDK8kDPu0JrH/JftesKAMOfW/9yzrvqugl8sP42l/3p7uAz/sC5zdf9xBrTKcz/fLdMx848JWYqtEHCX9/YvocfeFoTb+Y178oNnpcNqX240vaB+x4H1j+iOlx872i9HstAcbVOrXN3KSfMr3/3Ekgbpr1L3E9/7bi95BXjccibxa/9cFNVePISTJmSuRcvC2PHfpO/E45ZpmdO7MWOCpbaXV+U82Wj+uLm9Nk7/vKfrHdgj6ACu4CzDDrPKxSAY7OwLA3La8Z1MH0Pqelmi828SNS0D+/itS8vuDRHg4tEjUWn/exfOz8JjFdkXzQNLOx433g41ggz0ajs8u7K6//Xc3HUlYILL5PvJ5edX/ZFF4TjeYKM0XQ8H5b49RO5jnL8/UZAfnzAcsv2arqNAw9YHZYf9ycttw4HnngJQ8EyotNn3PkJ9ljRZUdhGtZXG3+PvU1BbaCm+CO4rdXKPDcKWDcfKDXQ+KY/s+/qhqX3CTLAFHjDXi3NN73a2P5PH1xsVeYqLHJSwaunTMGRboKy/dizaWdIrjVr8yKHi5+X9hq/LNUuwOOVZThdn8QGPsJjN9yAEK6mJ5jnqlxD6x+XPWIwY0dceNMIgXV5C/52kraJ34XZhiLSvXkX1byvXi2/EcUhf79qeX1cpOBf34z3j+zRixBlqTqA5W/PwXOrjc9VlYI/P0Z8P1YEcCY++1B0Whu/b+BkyvEFM/q6cDlPTXrXaHP3JgrqKLzbU2+0EoLgFO/i8Bp0Rjgoy5A8mHTLr95ySJrlrjPcsVPjtm2AjlJQPqZ6l+3KsPnGG+7+Zk+Jn8/8kyFd5iYxtEX2+ozN1VNj+UkGWtuPCrrcjyCALWb8ZzwXpbP0++P5REExIyqPKgC7vwKiLAScFdl8xxgyUQxBpWDKIwGgKM/Aef+ErflYzGnUgE9JwOxE43HzIMbtTtwy2vitn+0abGxArhayo5U3FyKSEH10GjKPcB4+8Ry8cV8cgUwZa3oSaKXfAiIHmoaoFSYZRwu7RJf5uY2vi5W/ax/SXyBjfk/62M5vcby2LKHjV9Oh38Abp5p+rg+Q3RSVlR6cav4iRpo/XXkqgpuji8DBr5gGSC5BxjrdA58DSQfEY3gnF3EsaIs4ItBQG6i6fP++U30VNHLTRZbExz4CogeZvn6Ds7itfJTgITtgK6Kfi4hXW3vYD3pd6D1ION9eebGwRnoOgHY85m4H9TJ8vmuPuJ3ddNSuUnGz6rNENHV2C9KZGSS9gEOTkCfx0X2US6jMmhTewB3fg30nQa4eIlAK369Mfhu0UPUwLgHiC7I1pz9U/z2jRLv2cnFWCitf43qyFeXeUdYPj5gJuDTEghoW/216hkzN/aSEY/Yg//G604/sOaGSAnyL1rzVT91Jc/OpJ8Ctv5H/D74jWk32SsHxG+TfitmX/z6FvvWrH1edME9YKWLLiBqJdKs7MSsD2wAUT9RnGOc0pF3zVV7Wj63qqmjpQ8Zp4isZYMAUcR6aZcIrpY+JDIxGfGmX35rnxeZgRPLjcdOLLcMbADxxSvvGyP/LM5vsjw/uKMICAHjsmwf2RTPTY8Bzx4D7vzSskhWzjz7IA9u3PyBSFm/GvMaE8C4cqokRwS25v129NfLTzV+ll0nAOMXAKPeEwHiyLnArHNAUEfL6+s/O7U74KQGWvYxjsM30njeqP8BExdbz/50vtv0fkA7wNkVGG0WRDvbyNzotR5cOR5P65k/Bweg671Ai+7VX6ueMbixl9J8hCeuxgjHg6y5IVKE7C/bmjQvqwl5LY1840Cd1jRzo6+NkHfQNZ+isFWDI9+3x9pfILs+rPq5ne8GoAKuHgb+1wr4PE6ML3Gf8ZzS3CqfbuHkCuPUmc2mcVvEl+/JFWL666tbrBdeH/sFOLZE3Dbfk0gvO0FMTenJ93KyJqSrsbmcPvhpGWd8PLSb+PIP6gA8f9oyiAHE1In5NJQ8e6HxANrcIn56TBIZE3P64EZbJv4MzTNITi6V2ydIxm0WXH2Bbv8SmRvvMCDuKTEOZ1fr2RAAVrOSbYeLKaaQrkB4b3HMxcfyvFHvAVM3G99bZH/xu8eDQJQsa2W+2skafe3NEzWsqVIQgxt7qYzQ/ZCP4vIa7BBLRPYl71lS080AqyPP3MgDEJWjaSCjn76RN5nLSwH+egXY+o64n1/FF7s587EXpBv/Ba+xsrrmpkdNv7zzroiaH/MVQbVxYYsIssynpVr0MGaBLu0yfayswHrvnUs7RVfjaxdMP0O9VpVftvIMzY73bI8vNNa0pwwABHc23laZfbVZ+9KXn294niyIULsDThrgwZXA7VbqpwCR7XCrnLrc9Kb47eRifLyswFiIbBiLlSBJL6Cd9eOOzpbHgjsBT+0FJv9hHLd89ZVPS+DubwF3f5HRef4M8PgOoM+TxnPk2Z+aBDeOTqL2Rp81a8QY3NhL5dy8m6oUBfm1+FcSEdmHfFWNeedZSarZPjvm5I3Y5BscFqabFjAXZQHaCtPgJmmvqNfY/j+R0civogjX3NZ3RCYo/YxYeXXkR7HLc3hv0ereXEA7yymNa+drvzxa7uJ2MY1iXqTt11pkHYCqd+iuStJ+y+Cmy71AWA9x21rgIydfWhzS1TK4kX9Rm0+ZaKwEFB3H2X69mtSgqFTArZUbaB77Rfx2lWWDygqB2z4yPWYt0NILbG95rFV/IG56FefHGOt+ANPgptsDQOe7jPc1niIolK+I0ndCBmo2LdWEsKDYXtQekBw1UGlLIRVeg04nwcGBO2kSNYi0U8biSsByWuq3B8U0zfQDpl8G1ZFPS8mzONcqAx2/NpXLkCUxDVXVxo4Zp6uekjG3dz5w+nfLa8VOFFkQc25+QJDZl2LmWes7VddUWT4Qv87yuG+kKH61xT3IdAdpvcS/RdNDQNScFGYAvR6x3MqgKv5tjNsiBHey/HzMgx05+X8PYz8Wy6o732n9XFc/8WfZ/raajavL3WLnb/17dvev3DVbEk0BQ7sCU9YAP94pprqs9bbRC5RlbnpPFdNALbrVbByA6bVtrX7Sk0+D6TM3w94UWaixH9f8dRshBjf2olKJqan8q/CRcpFTXA4/d7XSoyJq/irKgAVmGQ15H5bSAlFsC4j9kQxLamWuXRAri7o/aPqv/qqa1+mnfPyjxTlFmeLLOu2E9fOTD5tmgapjLUjqON60LkUu0KzY9dxGXPeyTfOVO4CoYTGfqho5V3wp/1SZJXBwEtmMP82aKR7+wXg7uLP40geMmRu9bg+IQmRzGi9gWmXhtsbDsj5FX4MDiD8Xuc53iQLqEf8Bek6xvLbcY1uBhJ2my55tUalEAKIP0sJ6AmM+BDa/JboeAyIYe/aYONfBsepreck6JA+fU7OpIjl5cOOoqf58+VJ3/WsNeE78GXgo26fmenFayo5Ulf8x+KvykJFfWs3ZRM1EQTqw6yPrK2vqWl2ffAjY/n7NppKs9VyR161cPVL9NVY9KXZzlmcRtOVV75icX1kc7Bdl/II4s06siDKv9wCM+0HJ6zFqI7izyAjcNNX0uL7Wxjxzk7DddiO9VlZ2rdbTd+LVLyOXC+poOa3S5W7T5dr5V4G+T4ol4FWRZ1l8Wples+0w8eVqztlVBFH67IaPleDmkY3A+IWWq4Z6TgZmJwH9qpjekfONFMW2VTW0sya0m/F21CAgorfI1ugDOEAsh3eqJuCIqCwM9o6ofWADmAY3VS2Pl5PXajnK/jHexAMbgMGNfVUWljG4oRvKkn8Bm94A/njWeKyiFPhiIPDz3Zbt82viq1vEsuv9VSyNlrO2Ckk+DSHv6FucIzq17l1gDHpK8oArlefINx+UZ23knWTlfKOMvXB2Vi6tjf0X0OUe0/MubhW/67rfjr6mpkV3YMYJ4IWLYinv/cttj68qvR4Cut1vzCwAouZi/EJg0uqqn+cfbbpxpKPGGNzFVtbitBkqfsvPC401vY58ybVKZVpIq/ECbvsAGPii6XPMAwMPs2koZxexS3a3KjIuGivL4e0lMMZ4uyb9g6ri4g28cAF48u+6PV+eFapJU0v3APFaTx+uWVPHJoTBjT1V/iXnhzxkFjC4oUbk2gVjnYi96Xu8nFlrPJYRL/bGOb9JdEetK1sN2PSsrUKSFxRfkQc32WK65c+XgC8Hi2NJ+0TBLmC6BFlfb6PxqrqeQ5650TdEaz8GGPq69fNt9VyxRd5ozieiMovzKOBZORXj4AA8sVs0F5SvhgHEUmZA7HjdeoioiWk7Ahj/udhPyXDdliIw8A4zdt4156Q2rVnyamH8Urz9E+C2D4FxlU3v5NmYFj1M+9CYT83Im765eItApv8zZq/tanpf4Q64JqKHiQxUx3GmjR/rwj3A9oqqmqppAX1wJ1HP1Myw5saeKjM3fqp8Zm7IPiRJbIwXGgtE3Vy3a5QWAJ9W1jW8lml9Wak9yP81ni/LppxcBYz8bx0vWoN/TVor1JWvFNJ3eQVE3Uv6SdNz5Uua866YnguIL1uPKr7sfaMstxxo0V3sP/T4TjE9du2cqIEpyQH6PWO6GzUgAg59ZsfcI5tE/5pu91t/XC6kcmlz5ACxuaK+t82o98WWBa2HiPu6ctMsyJN/i+0Zhr5hPOYdbiyQjRokprh6V25oKc/IyHfRdnQGej1svC8Pgtz8RQ3L9v9ZH7s8uNGvbFJ7iCk+SSfuO9dxSq8huPoAM2oQiDeE9reJ7sX6VW03KAY39uQu/nIPUOXhHDM3ZA9n/wI2vCJuvymbJsk8L+pSut5bfTo5M954uyjL+K99e5BPOVUV3FhbknztgghKqgvYzN+bTiemmUK6iBoMwHpws+lN0chuwEyxr49ecY7pkvHSfNPaEvm1DMGNj2WBqp53uGlw4xEiAhvAWG/RKk40gdPzChdBVLtbRTBQmFF1cBPR21iHURsuXsbgxqclECAbv4PZ9E5wJ1EfYv6+rlYWL8eMBu5ZZAxq5BkZW9Ns8vPc/EXXYEdn08Zxev7yzE1lcKNSiakk/fRgXeuVbjQTfhKZy7rU7DQjjSiv1wxU/iXnhzykM3ND9qDfxdfcZz2BlY8Bp2zUR+hlyIKb61keLFdeDPz6ALDpLeMxeUGivA6motiyMd0v9wHf32ZsfCZnq0Zn/xfAN8OBxROAEytEAJNvpeYGALa8LbIPWtn1irNNN8DMOFt1Z1x9UOTma31/I2c3sdzWW9Z/xXzljzUP/wnc+j/grm+AdiNtLw2uK3nPEqc6rNqUZ2TcA8Ryc32gKc/IWOsfoyfP8Lh4iwLdgS+Iuhhz8uJg+TXlTQutBTf9K+u89BtBkvhzusEDG4DBjX35iIZIPRzOIfNaFbvDEtVGdUWB+noXW+SdaouzxNLpA9/Y3g5ALjcZOPyj6X5Np1aL5dV75xuPyZc6mwcc8pVU2nJj0LbrQ+MybcN18qoey87KFTgJ24FlDwHrX7TdP0a/LYJ8jJnnjPdPrhD1Nvov1Pyrxh2+9R1zW/UHWva1vLY+U9XpTjHdFNi+Zl+yPhFA3yfEcmbAdMlul3uMhbI17bNizfV+uZkEN2bTbvIpLVuvIw/abC1/BsRqsFb9RS2Qs6y2Rl57Yi24GfIqMHkNMKKu057UXDG4safIASjxioKPqhADM39RejTUHOgLXQFj7xatLOCpSao+XVZzUpQFbHgVWDtTBAc18eN44PfpxtVAgGlzO8MxWVbIPLiR71Fk/tjaWWJcusr3Kl+lZN6MT19/oXfga9vBjXnmKyfJdOm4fg8lee+br24R034XKqeK2o4Q0yld7zO9lj64cXYBRrwNTNsndgavrcj+IqBp2Q+462vg6YPAHV8A4+ZX/9yq2DW4sVEgK5+KNCcPaGxlePTnPrQOuH+p6VSk/HnWam6c1GJqszHX45AiGNzYk4MjtP1EmvRR3W8oO/qbwgOielFRWvf+LbWlkwU3c8NEa355E7XEvaJ40Jb008bbxdliagcQDe1qQh8gHJUF7PLCW72yAmN2xzwrJN9QUT/1o88IFKQC70WJ/YcA000ei3NMM0byz0Mv53LVY79UWU+jXyotLy4GjEWzIV1Et2G99S+IHjfuQcYeJuM+AyYuMZ5j64u9NtTuosGbvu5F4wnE3le7Tsrmbn5e/K5ui4GqeIYab5tnbgDR6C2ok+gfY8str4oMVNsRdRuHSebGterziMwwuLEzt5smYwXEqoTi0xsVHg3ZXUE68H9tgRWPNczryaelJJ1YbSLPfFzeJepXzKdf9LQVxpb1gGWWQ1vNtJecfJdr+R5Kk1bDsKpJPzWlH6O+a6y8qFg/noB2pv8yP75UBI3yzE3CduDTnkDSAeCnu2vX5RcwNrIzNFOrIij1ChPLmPX7F+mb7rUbYVxy7Ohsun/R9S75lXN2qX7qpjbaDAGeOSrqeupCnrmR74ukN+xN4Km/q68XGvgCcN/PtWuIJyffT0pew0NUDQY3dqZycECSu/iLtCy3mo3gqOm5clB8+SbubZjXs9arwtoGjOlnLI8BlUGF7Av95ArTx7Mv1XwsZQViPAsGACdXimP3/gC0Hmz8kivKEvU1+mko/c7L+vt/fwYsr1xS7BVmucQ6O8Fyy4PcROCbYcD5OvxjQZ9hku/P4+QqtgyQ8woTvWQe3Sp2/NZrO9L0PHmhrpsdg5v64BdV92X/Xi1EYDRxSd0DE3sY9oZoNHjLa0Db4cqNg5ocBjf1QO1d+a9Va5vHUdOmzzpU1Zbf3uTLlvWsraCqalWV+T5A5tMy8mXiNZFxBkg7bryv/xe+/l/Vn/cR9TyAmM7Rd24tzBRZIv2ydkB8gXqYLUu/etR2QXFNmHeuBYAOtxtv95hkubu2fkmzZ7Bp87g2Q0zPk9eyNPdMQpe7re/D1ZBcvEWjwYGz6q8/EzVLDG7qgae/+IvSucRKfw9q2vTTMfKNGeuT+RJqwPqeP+mngfISy1ogawG2xsvYIl8e7GgrgB/GAaumia0JFt5sutkhACw025NIv9GffEpFvzx94CyxhBgQGSJ90KPnGWKZuUk5WvVmlbbIN458/ozpFgKuvmIKzKeVaAzX72nTvir6segNeRUY9G9R1Gvesl+euXFmDQhRY8UmfvUgPLwlcBxwK88WXzbNbM+OG5o+c1NRLBrKXU8L+Lyr4svWxUsUzSb+DUT0FUttteViJUhZvuXzLlvZd+bcX8B7K4HOdxrb3wPWN7Nsd6vIqFzYLPq86CUfEhs/AsCxxaLG5/enbb8HfbGpfE8mAIAKiB5ufP1Tqyyf6+pnmWVJ2GncLqA2OowVWRW/KPH/W9Qg8dmWFQDtRoljUzeJLRLMN1wETLMCjk7AkJetv448oGFwQ9RoMbipBx2iowAAapSj5MD3cOk9mQFOcyFv8lZRXPclt/lpwAcdxBf8rHPAz3eJ4tehb4juvaf/EEuLrWVuzJdHA8bppyM/ijqbm58XAcylneK4m7+xqDeyv3GljzxzI1/Kbb7k2ppejxiDu64TxJ5Nej4RokhW3lZf5SheO3q4WOHU+U7TYmdAdMW1Vqjb50kR/KUcsz4WjSfw6GbZa6mAx7YB+xaKLAxQ9RYKtSH//5jBDVGjxeCmHgT7+6EILnBDCVzWPQs4SGIXXmr65Eugy68juEmqLEguzgJ2vG9c1XNuo/gSB4Bjv4h9oWorfp346TjemDHxjZQFNzcbg5eUo8Cp30XmwzzQkPOOAMZ+BPx0l7h//3Kgraxr78i5oufO4e/Fff20T6v+wIOrxOqptiMsAxf5curADkDGaeDcBtNz+j0j+shsnWsZ3Ax4Toy/+wOWYw5oC4yZV/V7cvGp/eoruYg+dX8uEdUr1tzUk2In2RLJ48uUG8iNqqwIyLpo32vqdKb9W6xlVbTlwJVDthvLAaaZke3vGm/Lv7wdnS2zNL5RgF9rsX9MdeRTQZEDRCdc90DxfN8owKFyKua3B4EjP1muAJPvDO3iI5rM6QV1MDvX39gKHzDuMqxSiaLcbv+qful0zynWj+t7rtw8U/RN0fNpKZYkP3PYWNtTG/f+AKg9a98s77mTwGPbm+VOykTNBTM39cRbJyuK5JRUw/vhdrE1weM7ZT1OrkNFGZCbJHZU1is3KyqWJODroSJA8QoHZhw3TtukHBOZB22ZyIBkJZg+N7C9mCKSr8IqybMMbka8LbIsuhpMG8n5txWN4pxdxX+Pjk6m7+X36ZbPadXPGCC5+oh9lB7ZCJTmme6npOfT0ni7uo60emE9jbdbmmVCOo4X01f6TSedNKJvSodxIts18IWavUZVWg8CXkqsfd2Ud7hpHxgianQY3NQTJ12J4baUeRYMbxqYfs+lY0vsE9wsGgNc2W96LGmfyILo99opSDdmXvKuiGkeffHqtv8BZys7CX/UxfL6YT1FtilX1owvP8VyWkq/Wkf+hezqZ9pgzxoHR+Nu1XotuotVUVWRBzf6ZoLWNj3Ukxflmmd2qhLSGZj8R2XAYFboe88i6/8wCGwH3PVVza5fnespCCeiRov/Z9cTbae7DbdVBWmm7eepfsnb9WvLREZl69zqtymoiiRZBjYA8MezwIpHjffNVwzJ7187B5vcA4DgTqbHCtIsMzfyGp+BL4r6mQEzZNcJAm7/1HTPKZWDOM/cuM+BFjZ2sa7cCBaA9VVX1jy4Ehj0kthMsqaiBoog0byPCTOeRFRHDG7qieNt8/B/nv9GmuQjDqRWscqD7E++MWJpPnD2T1HX8st9VT/HFmu1NXr6ni6AZXATvx74sAuw/6vqOwG7BwLdJpoey00WS5fl5H1WbnlF7Eck75T7fLyYxpm2T6y8mnUemHHC+vLn4I7AlLVVj0m+usi8GWBV2twCDJld94yIfqrJvIMwEVEtMLipL64+KGg7Dtu03cT9k6uUHE3zVJBhPaMgL/r9Zwnwl6wrriSJ3i7WNmCsSnVN5S7tFg3wzIOb/V+IaaZ1s0QGyRb3QNFFN1YW4Fj0joFpcKPX4TaxfUDH8cagwjdSFOB6BFqvj9FTy64X0cd07ySPYONO2PKuvfVp0L+BqVuAPk80zOsRUbPE4KYe9Wjli1W6/uLOyVWigyzZR0kesCAOWNDfMrNivqQ564Lx9v4vgfm9gd0fWb9uThLw5WBRq2N4rWqCm0WjgT2fif40gNhhurbcA8Q0zPgFovAXALSllueprQQ3Lt6iePmeRbV/XUAUXd/+KfDwX6YrntwDgbEfAw+tB/o9W/Xz7cnRGQjvyVoYIrou/BukHvVs5Yu9ug7IkLyB0lzRU6QmSvOBr4cBO/6vXsdXK6fXGHuxNAanVompkoJUy1oa+a7Z5ta/KH5vnmM8ptMBP94B/PogsLpy64GVjxsfNw9uHMxqQwBg0xvGupp2ddiPR9/pV6UCvFuabt4oZy1zA4iC4brWqIR2FVNZKhXgqDYed1KLRnyt+im7eSIRUS0xuKlHLbxdEOTlijO6ynqHzGqKSvUOLRKrfba8XW9jq5X8VODX+4Hvq1iCnHdV7JbdkOSZFXlnXP14aqKocoVR5lngwhbg9O9AwnbL88yDG7/W1q+n37yyx4PWH7fV9E0f3AAia9Gyr/G+Wra/UVXBjb10HA8EdQT6PlW/r0NEVI8Y3NQjlUqFm6L8cVGqXIJ7aaeoE6mOvA1+Y1CcY7xdZGXV10ddRX+X1BOmx3OvABvfMG42aQ/nNonsinzzyEu7RC1NaQFw+EdjrUpQJ+vX0NPv0SQvQJbTVvaBMQ9u/KOrvmZoN9HvpZ+VGpU+j1se03Mza3B351ei0Z5vFNB+jPG4kxr1SuMBPLUHuJUFvUTUdDHXXM/6t/HH6RNil3D886v4Qn3miOWyVzl5sWtZYd1b/F+PQ4uAvQuAib+Y1n7kp4giVT1JMjaDu/y36Fuit3gCkHYCSNoPPFzHZdjmfr7L8lh5kWgst/09UfuiN/Q14Mxasd+SNcmHRDFuTpL1x98OEAGSPIvS6Q5RvFuVdiPF71teFY3sAtuJzr+d77Zdi2MetHiHAdP2i+mmNTOqfh4REVlg5qae9WsTYMzcAKLL7bFfRMM3AIj/E/hhvOlSYXlvE/kS3Eu7gZ3zat+dVi4vRSxNrrCyekdbIfY2Ks4BDn4nOuZe2GpasJtvluUokjWPM6/5SKvM5CRa2cW6Ov8sBU6utByfnLO7sRNufhpw4GvZWBxE/xRPs12nAWNdib7QOCfR8hy99JPAwW/E7R6TRdGuo43sSefK/kZOGmDQC0DHcSILEt7TNIDxCDbuv1QVJ7UIbiTJ9nlERGSCmZt61tLfDRW+rQH5gp7fnxYFo0NeNtbV/PUKcN/P4rY8gCjMNC7PXTRa/Hb1q/tGnD/dJb6wcy4DI/5j+ti+BcCGV8Vmh/r6kYPfmn6Zm0/hyFcm6Tch1GlF/Yqec2Xmae0sIO0kMGmVsauvNfmplc3xJDGl1e9pcTzbbMsCd3+xX1JpnhiXe6AIHgHAI0RkvDyCLa/f/jbg5ArgWuXeU7lVZG7MuVTuF2ZtWfegl0RWJ7Cd7Wt0uVfU9zy1F1B7iGXi0UNtP4fBDRFRrSiaudmxYwfGjh2LFi1aQKVSYdWqVdU+Z9u2bejRowc0Gg2io6OxaNGieh/n9Zp1zzCkSmYb+0la04Lh+PXGni3mwQ0gVlDpJe6x/YLmGQ659JPi99FfLB87+J34fXm3cd+ktBPA1cPGc7bONa2tkRfv6rNRJ1YAS6cYj7t4ix20D3wlsjiXq8nkpJ0AUPmFvuFV4INOwN6FQPop0/Pc/I2ZmayLpkHK2I/Fb2uZG30NS9ZFETjYytyEy7Yb0Ac35cWm53S7XzSuC2pv820BAO78UjTac/MTmZnbPxHZHVuk68jUERHdgBQNbgoLCxEbG4v582u2K29CQgLGjBmDIUOG4OjRo5gxYwamTp2Kv/76q55Hen16Rvrj25gvMbHsFZSpNNY3FZS0wPGl4nZBmvG4floqTfbFnhEvfpcXAyseA07JsiR/zgbea229I658KkpnJQBS1eA/h/yrwJeDjPflmRv9uC+ZLRl38RZTXHrV7YOUftr0ft4V4M9/i2k5ObcAY/CiX6buFgC8nAK0G1H52j6W1287XGTOyguBb4abFieb63i76fsAgApZDdL9y4HRtViyr9+0sjbCbGyRQEREFhSdlho1ahRGjap5T5CFCxciKioK8+bNAwB06NABu3btwocffoiRI0fW1zDt4vZBN+HLf8pwS9kHWPvMKHgviAXKKrMx/WeIpnLHl4qsgjwDYQhujhuPpf4jWvMn7RNFypd2iZ2iVSpg7+finANfW047yTveluaLL+kd/ycyA7e8WrPgBhCBUeE1MS1kEtxUZm7MV/5UlJgGZ7YyJQCQfsb68f1fmN538xfN7wDg4jbxO6iDaaM7+U7Vei7eYqPGnMvGDTarEjlA9jyfyteVZeHaDrP9fHvo+ZD4zKMG1v9rERE1A02qoHjPnj0YNsz0y2TkyJHYs6eaaZpGoHOYN2KCPXFF64tNF4tNi2/7PiUCi+RDljtG66el5FNBkg74+W7x5QyIACPznGnhr7Wi1wxZRkTSAhe3AzveA3b+nwg4ahrcAMapMZNpqcrMjXlmpiRX1Nro2QputOVAvI39juT9YOTTUvol6m2GmJ7v2wq490dRCBzaDbj1XXE8MMZ4To/Jpku3HWX1QEEdjbdL88Tvm2cCMWOAe76vepz25OgE9H3ScmNNIiKyqkkFN6mpqQgONi0QDQ4ORl5eHoqLi60+p7S0FHl5eSY/Srm1s/giXnc8BbkjPhQHb3kN8AwGuj8IwEqH2b3zRVZCX6A74j+iEDX9lOj5ondhi2lmpsJK637zjMgxWd3NP7+JKaeaurRL/LaWuTHf76k4S7wPPVvBzU93Gfv8eLYwfWzcfOCRjcb7bn6Ap2wlWlhP6/1lOt4uin0f3y6CBAAY/BLQ6xFg6mZR9yLP0MgDJCeN6DUDAK0Hi9+uvsDExUCn8VW/DyIiUkyzXy01d+5cvPXWW0oPAwBwW9dQfLz5HDafSUfsGVc82X05/j3gFvHg7Z8Yi2CT9otgZXtlluGHyoLTgHZiQ8Hzm4GLW4HLu4wXv7DFOEUDGAMNOf0UjNpTTImdXGF8bOt/LM835xYAxN4nesnsW2DsYaNXViAa6emzKCFdxRSaufObgPl9RMfesR+LLFZuspiW03cI7nKPqIv5p7IT8RO7RJ8YeXbK2dUYeKg9gbu+tt0/SC6sp/jRaz1ETPu06A7c9LgIYPRN9x7fIaYH/dvU7NpERKSoJpW5CQkJQVpamsmxtLQ0eHl5wdXV1epzZs+ejdzcXMNPUlINl/3Wg7bBnnhkQJTh/oIjpUjNlxX5qlTip2UfoPcjplMwADDwBfHlHXETLFzaZTr1Y75kW1thDG5qssOzg5W4t88TwPC3gcibK19zp+XmjqnHjcHNyP+aXmfoG8bbGWeAw98DJ5aL+ysfF/szAUBwFxGouPkbz/cOF7/lDQ0lnSi2vf0zYMqaqrdFqAknNTD5D2D4HNFA746FItABABcvBjZERE1Ikwpu4uLisHnzZpNjGzduRFxcXJXP0Wg08PLyMvlR0r9vbY/XbzPWcfy877L1Ez2CgOfPmh5rO1z8Du9teX55IXDkJ+N9eeYm+bCY2iorADTelVNg1bC2xYDaTex7dNc3ljU9+uXMm94w9shxDzTdALLHJOOKI73lj4jl3pd2Go/pgzf5Emhrq578WotgsMeDQItu1b8nIiK6ISga3BQUFODo0aM4evQoALHU++jRo0hMFDUZs2fPxqRJkwznP/HEE7h48SJefPFFnDlzBp9//jl+++03PPfcc0oMv07UTg54eEAUPr9fLO9dvC8RJeVa6yc7mP3xuPqK3+G9TYt/9ZmUQllAo++Vc3oN8NUQ47YFLfsAXqHG6RwAaGklOAy00rNFnzXxDBZFunpu/mIaCRAruAzHA0wzO+4BosbliV3AqxnG1/j7U9PX0QdK8myJvAB78h/AsDeBmNGWYyQiohueosHNwYMH0b17d3TvLtL/M2fORPfu3fH6668DAFJSUgyBDgBERUVh7dq12LhxI2JjYzFv3jx8/fXXjX4ZuDUjOgYj1NsF1wrLMPC9rTialGP9xLsqW//fIVsG7eoDhPUy3u8xCRZKcoBvRgDLzDoZt64slr3zKyB2oliG/tB6IHq48RwnF9HFt/+zps9Vexhv67smA6Lwt81QwCvc9Hz5kmm9gLaidsZJDYxfAPi1AYI7i0zRvT+KvjGtK/vo9JgspsLuX256jaiBwIDnLLd7ICIiAqCSpBurt3teXh68vb2Rm5ur+BTVD3su4fXVok7G1dkRa54ZgDaBHpYnlheL4lm5EytE4OKoAf6dALxTubLIwcl6gz69GScAnwjL49cuAF8PE0W0N88yNpqLXw/8cp+4fd8vQPvKbElZEfBO5UqliD7AIxvEOBfeDFw7J46/mQu8KZuGetNsd20iIqIaqs33d5OquWluJsVFYvsLg9GjpQ+Ky7X4ZV8VS6TNAxsA6HwncPd3IqhQuxsbvPV9UuxkLaevj1F7WA9sADEF9OJFsURa3kFXXiMjL+aVN8rT77Xk7CrqX6y5nmJfIiKiWmBwo7BW/u54crAo3v3tYBKKyipwJbsI2YVWNmc01/lOYyHtvT8Ct30IDHkFuPcHcVvv6cOin468R4w11qZ5TIIbK1klwLTwN2666HY8eY24f88iMfXUUA3viIjohsdpqUagrEKHPu9sQnZRueFYqLcLnhrcBje3DURkgLuNZ9twcZvI2rTqV/fB5SQBH3UWt5/aK7Y30Ns6V3Q4nrwGiOxf99cgIiKqBqelmhi1kwM+vq87Wni7GI6l5JbgtdUn8eTPh1Hn+LP14OsLbADR40VPvqwbEDthv5TIwIaIiBoVBjeNxMB2gdgwcxAeH9Qa3q7GLrunU/Jw4FK2cgNTexpvewRZPq7xtDxGRESkIE5LNULlWh0+2XwOv+xPRGZBGfq29sPjA9tgQNsAODsqEI9mnhN7VYV0bvjXJiIiQu2+vxncNGLn0/Mx7IMdhvsuzg54dmg7TL05Spkgh4iISCGsuWkmooM8cXuscWfsknId/vfnGfy8t4otG4iIiIiZm8ausLQCq44mo7hMi/+sPW043quVL967uysCPDXwUDvBwYHdeomIqPnitJQNTS24kSvX6jD64504l15g8VhLPze8dltHDO8YrMDIiIiI6henpZopZ0cHrJzWH4un9kG/Nv4mjyVmFeHVVcex81wGdLobKl4lIiIywcxNE5aeV4K/L1zDrKXHUCELaMbGtsBzw9qitbV9qoiIiJogZm5uEEFeLhjfPQzn/jsKwzoYp6P+OHYVt8zbjt8OJtW9ASAREVETxcxNM3H5WiEW70vE2bR8bI3PMBzv3tIHA6IDMLxjMLqG+yg3QCIiouvAgmIbmmtwI6fTSXh/Qzy+2ZWAsgrjppaPD2yNB+NaQaVSIczHyk7jREREjRSDGxtuhOBG72pOMT7fdh4/7U20eOzh/lF4dUwHLiEnIqImgTU3BABo4eOK/4zvgnXP3IwIP9NMzbe7EzD1h4M4nZKHtLwShUZIRERkf8zc3EASMguxeN9laJwc8dXOiyiVTVndFOWHR29ujc5hXvhyx0UUl2nxzNC2aMHpKyIiagQ4LWXDjRzcyJ28mounfj6My9eKbJ4X19ofH0yIRag3gxwiIlIOgxsbGNwYlVXoUK7VIbe4HIv+voSvdl6Etf8aukX44LN/dUegpwYaJ0fDcZ1OYs0OERE1CAY3NjC4qdrZtHz8cewqbo9tgZJyHRbuuIC1/6QYHndxdkCwlwv6RwdAkiT8fvQqHh/UBk/fEg2VikEOERHVHwY3NjC4qZ3jV3Ix/Rfb01dvjO2Ih/pHNeCoiIjoRlOb72+nBhoTNVFdwr2xbdZgFJdrcSmzCEeSsvHrgSSoAEClwrGkHMxdfwY6CSgqrUBWURlu7RSCPq39q7s0ERFRvWDmhupMp5Nw31d7sT8hy+S4o4MKj97cGn7uzsgqLIdKBTw5uA28XJwVGikRETV1zNxQg3BwUOG7Kb3x497L2H0+E67OjriaW4wTyXlYuP2CybkqiADntVUnoFKp8P7dXXEluxjBXi5wVTtafwEiIqI6YOaG7KqkXIsvtl/E6ZQ8uKodUVymxZ8nUy3OC/V2QUpuCfpH++PxgW3QJcwbvu5qBUZMRERNAQuKbWBw07CKy7To8Pqf1Z6ndnLA+3d3hberM5JzitG5hTe6hntzFRYREQHgtBQ1Iq5qRzw+sDV+3HsZb47thFFdQvDUz4dxJbsYCZmFhvPKKnR4dslRk+dGBbhjULtAxIR4YmxsC3hoLP9z1eokOKjAIIiIiAyYuaEGUa7VwdnRdCuzrMIyzNsQj7GxLfD935ew/kQqAjzUaBfsiWNJOSgs05qcH+LlAj93NQI8NbiaU4zekX7YeCoVHUK98MPDNzHAISJqxjgtZQODm8ZJp5OQWVCKQE8NVCoVCkorsPLwFSRmFWHZoSvILiq3+fw/pg9ASz83LD2UhDu6h8HfQ9NAIycioobA4MYGBjdNz4WMAizYdgHBXhrM32pchXVTpB/2XzIuQ/d2dUZucTnah3hi2ZP9kJZXAne1E1QqQO3owIJlIqImjMGNDQxumrYPN57FiiNXsOihm9Am0AM7z2XgwW/2V/s8f3c1fnjkJnRq4d0AoyQiIntjcGMDg5vmZ/3xFDz582HDfX93Na4Vllk9199dDR83Z2QWlGFkp2D0ifLH8sNX4KZ2wmf/6g4XZ/bcISJqjBjc2MDgpnk6n16AN38/iak3R2Fg20DkFJfjWFIOHlp0wHCOSgWru57L3dkjDPPuiUVRmRb7E7IQ5uuK6EAP7n5ORKQwBjc2MLi5ceh0Ep76+TCKyrX4ZnIvlJRrcTGjEOfSC+DkoML7f8UjOacYAR4aZBaUGp53c9sAXMwoRHJOMQDA08UJPVr64s4eYYgO8kB0kAecHBzgyICHiKjBMLixgcEN6RWVVeBqTgnaBLrjhz2XsWDbBaTmlZic4+LsgJJyncVzPV2c8FC/SGicHXFL+yB0CPVChVaHcq3E7SSIiOoBgxsbGNxQVXQ6CcsOXUF+aQUCPTUYEhMIF2dHHEvKweurT+JUSp7V56lUQLcIHyReK0J2URlaB3pgSEwgXhrVAfkl5Vh+OBnDOwSjpb8b0vJKkJxTjO4RPqjQSXBUqTjlRURUAwxubGBwQ3Wh00koLKvAq6tOwNdNjbS8Eqw/Yblnlpy8sNnLxQnTb4nGp1vOI7+kAp3DvJB4rQgxIZ54aVR7RAd6wtuNu6YTEVWFwY0NDG7IHsoqdPjrZCr6RPlhzppTWHc8BTOHt8PY2BZYezwF8zachVZX8/+1AjzUmBwXiZb+briSXYztZzMwbUg0ooM84OrsCD93NSRJwoWMArQOYIEzEd14GNzYwOCG7E2SJOSXVsDLxZh5uZJdhNMp+Th+JQd92/jjX1/tAyD2y3p9bEc89sNBlGtr9r+ep8YJL45qj6SsIny54yKGdQjCQ/2jsPzQFXi5OmPGsLbwcWODQiJq3hjc2MDghpTw18lU/LjnMt4a1wltAj1wJbsIWp2E349eRXSQB64VlmHpoSs4lpRT62u38nfD15N6IdjbBV9uv4huET4Y2iHIsNdWSbkWD36zDyqVCj890gdqJ4dqrkhE1PgwuLGBwQ01Zk//cgTrjqfg56l9kJZXguIyLXKLy7F4fyIuXyuCg0psM5FdVI7ekb5IzCpCWl4pPDROKC7XGqbC2od4omOoF54Y3AbLD1/BF9svAgCeGNQGL46MQYVOQk5RGb7ZlYDici2eHx4DDxenGi9vT88rgYva0SRbRURUnxjc2MDghhozrU5CXnG5xT5Y5VodjiTmoGu4N0ordDifXoAeLX2QVViGJ38+jP0JYo8tRwcVHB1UKKuwXL5eHVdnR9zWNRRDOwQhPrUAa49fxSMDojChd0sAQHZhGQpKK6CTJIz6eCcifN2w7tmb2e+HiBoEgxsbGNxQc1NWocM3uxJw6HIWbu0cij5RfljzTwpWH03GmdR8uDo7Ykr/SJSUa7FkfxKKy7W1uv59vSNw4mouzqYWQCdJaOnvhosZhQCAiTe1xKS4Vgj3dYWnizMSMguRmFWEcF9XSJKE6CDPaq9fVFYBtaMDnBw5XUZEVWNwYwODG7pRSJKEjPxSeLk6G/bMupRZiHkbz6K4rALp+aWYObwdlh9Oxrb4dDx2c2ssO3wFJeVaeLk441x6Qa1eLzrIAwmZhSarxO7sEYZ/39oeSw8mIa6NP4rKtPB310ClAhZsu4BjV3KQlFUEP3cN5ozrhNFdQu36GRBR88HgxgYGN0SWKrQ6i8xJQmYhXl5xHKl5Jbizexh6R/nh1VUncD69AO1DPFFcrkWFVjJsU3G9nB1VeHVMR7hrnDCwXQBOXs3DiSu5cNM4oXMLL7Tyd8fi/YnYcTYDTwxqjRY+rqjQSege4YOlB0XzxclxraxmgP46mYpzafl4anA0l9ETNVEMbmxgcENUd2UVOpRpdfDQOBmO6XQSJny5BwcuZWNCrwjMHNEO+SXluJRZhKcWHzap/3FXO8LF2REVOgn5JeXQSUCYjys8XZxwJjW/TmMaEB2AXeczAQBDYgLxxYO9oHZywOVrhbiSXYx2wZ7o/d9NAICFD/SEv4caAR4aRAW4X8cnYVtCZiFScorRLzqg3l6D6EbD4MYGBjdE9pdTVIad5zJxa+cQOMsyJ1mFZUjKEp2YL2YUom2wh8njJeVaqFRAblE55qw5hQsZhUjOLkJeidgC4+a2AUjPK0V8Wr6YYnNxQl5Jhc2xtAl0h7vGCf9cybV4LMhTg/R84yapni5O8HVT49Gbo+Do4ICU3GL0bOWLknIt1h5PRbivKwa2DUS7YA/4e2iqfM28knKsPJyMsgod7u0VgVEf78DV3BIseawv+rb2r81HSURVYHBjA4MbosatXKtDam4JwnxcDVNIkiRh78UstA50h7OjA1YcvoKRnUKQmFWEJ346hAqthBdGxuDd9WdQphWZIicHFTxcnJBTVH7dY3J0UKFXK18Ee7ng8rVCODqoMKpzKPzc1fBzV+O/607jfGWNUit/N1y+VgQAuKV9EL6d0huACIB+P3oVIzuFINDTGChJkoS84go8+sNBdA33hq+7GqM6h6B1oMd1j5uoOWFwYwODG6LmJbe4HPkl5Qj3dUNKbjH2XLiGCq2EAW0DEOSpweu/n8Tf5zNRWKZFRr7oCfTYwNboEOqFNoHuWHIgCT/tvYzSCp3VLTNqki2y5b7eEZgxrB2e+OkQjlY2aRzXrQWevqUt5qw5hX0Xr6HUbOl+sJcGq6cNgLvGEQWlFQj1djV5PLuwDD5uzoZGjYCYMqzQ6eDq7AiVSoWrOcV4e80pTOkXiV6RfsgvKWcnawUduJQFFYBekX5KD6XJYnBjA4MbohtThVaHUyl5CPDQoIWPq9VzUnNLkF8iMj3ers4I9NRApVJh5ZErWLJfrPiKCfbE1dwSfLTpLPIrgx53tSNWTx+Af3211zDtdVePcCw/fAWAyPyYB06uzo41Wpbv6KDCgvt7YESnEBy8lIVfDyRh6aErGN+tBT6c0A0qlQobT6Vh9orjyCwQr90h1Av5JeW4ki2Kvf3c1cgrLse8e2MxqF0gfNzUyC0uh6uzI0ortDiSmIO+rf2hdnLAwUtZOJOaj7t7hhtW2Z1IzsWspcfw/IgYDO8YXOVY80rKsezgFdzVI9zqRrAl5VqsPJKMge0CEVbFn0FzVFhagU5v/AUAOPnWSLjLatao5hjc2MDghojsobhMizKtDj/tvYy4Nv7o0dIXf51MxU97L+Pft7ZH5zBv7E/IwovLjuHStSJDv6EVh68gLa+0yut6aJygdnJAVuWO8rbEtfaHt6sz/jxpe4d6OVdnRwztEIT1J1Kh1UmGwGtYhyDc3DYQb/x+EgDQLtgDd/YIx68HkpCQWWh4fsLc0VCpVMgpKoNOEoGT3kvL/8GSA0km03GAyK45O6rw9OIj2HwmHR1DvbDk8b6GDtfZhWW4VliGqAD3Rt0UMimryGS6tKbOpObh1o92AgD+mD4AXcK962N4zR6DGxsY3BBRQyou02L54SvoFuGDzmHiS62wtAIzfzuKE8l5+O2JOPyyLxGhPi7QSUBcaz+UlOuweH8ibusSiq92XsTW+AzD9Xq09AEAHE7MMXmdsbEt0MLbBSXlWqw7kYqMygzS+G4t0C7EE0sPXjEJUuqqbZAHisq0SMkthpODA8bGtkD7EE9czCzEL/sTDedteG4gVh1JxtrjKYYaJHMvjIzBnT3CMH7+bqTllaJ7Sx/88mhfFJdpsS8hC4cTs/Fw/yiEeLugXKvDC0uPIT6tAMM7BCEpuxhDOwTBQ+OEk1fz8ECfVlazRdak5paguFxrdcWcTiehoMx0I1ydTsKcNaew6O9LGNYhCF8+2KtWAc7GU2l49IeDAIAP7o3FnT3Ca/xcMmJwYwODGyJqSiRJwsXMQiw7dAUhXi6YFNcKKpUKJ5JzcfJqLtLyStHSzw23dQ019Pi5kl2EV1edwJ09wnF7bAsAohP0lexifLnjIvKKyzGkfRA+3HgWA9oGoKxChzX/pAAAfN2c8d7dsfjv2lOo0Elo5e+G3eev2e39tAl0x4WMqoOsDqFeSMgsQEm5qENyUztiSr9InE8vwIZTaTavPbpLCAa2DcSE3hHYn5CFYC8XRAa4o6xChxNXc9Et3AdlWh0Gvb8V1wrK8MtjfdE70g8JmYXw91DDy8UZLy47hhWHkzG5XyTu6B6GzmHeWLwvES+vPG54nQf7tsKsETGo0Ong567GlexiqJ0cEOzlYnVc3+xKwNtrTgEAnhzcBv++tT0AMd333e5LmNyvFbqG+9TmY7whMbixgcENEZEgSRJUKrEX2cHLWejZyhcaJ1Fno9NJUKmAcq2E5YevoE+UH3aczcDlrCIMiQlC60B3fLH9Iq5kF6GgtAJ5xRXIKirDfb0jsPTgFaTmlSDU2wUvj+4ARwcVpi0+jHBfV2yaOQiZBWVYefgKFm6/iILSCrg6O+LhAZGYv/WCXd5XgIcamQVlcHZU4ea2gThwKctQHyXn7eqMMV1DsXhfItSODujYwstQ9K333zs644MNZ3GtsAztQzyr7Mfk6uyInx/tgxAvF7z/VzyKyioQ4uUCF7UjrhWUYdkhUX81rEMwvp7cCwDw6A8HsbEyYFv2RByu5pagpFyLkR1D8L+/zmBITBCGdwzGpcxCLNh2AZezCjHv3m44lpSDfRevoVekH0Z3CcXfFzLRs5UvdBJwJiUPPVr6Ymt8OorKtBjdJbRWU33HknLwfxviMTa2Be7pGW5StK40Bjc2MLghIqpf6XklOHApG0M7BJkUJQd6akyyG5IkIbuo3LDb/WdbzuODTWcRG+6DXx/vi3kbzuLLHWJH+0BPDV4cGYNbO4fgpRXH0TXMGxF+buje0gcHLmVjyf5EuDo7YvOZ9Hp5T20C3fHnjIFYdzwF76w7bbVuylPjBD8PdZXTcHqD2gXipig/vP9XvM3zXJwd8MroDnjj95OwspAPANCrlS8OXs5G+xBP5JdUIDmnGJ4aJ+SXGoO5O7qH4dUxHeDrpraYTssrKYezgwNc1eLP6f6v9xoyda+M7oDeUX7oFuFjOF9fp5V4rQg/778MXzc1HuzbqkGKpBnc2MDghoio8UrPL4GPqxpqJwdIkoSconL4uqsNWSZbJEnCZ1vO43BiNga2C0SotwsSs4pwIb0QZ9LycSwpB+5qR3Rv6YvP/tUdv+xPwiebz6FfG38MjgnEwu0X0SvSF2+M7QRvV2fMWnoMK48kw9FBheVP9jN8yUuShILSCugkYP7W88guLMPBy9mGmiaVSgQUey5cQ0puiV0+lwHRATiSmI3CMi0cVICfu8awOq6muoR546VR7REd5IEDl7Lwx7Gr2HQ6HVqdBBdnB/SO9MPOc5kWz3vtto4Y360Fpi8+gn0J19A70g/XCssMvZ16R/ri+4dvQnJ2MQ5dzkZ6fimCPDW476aWdnnvek0uuJk/fz7ef/99pKamIjY2Fp9++iluuukmq+cuWrQIDz30kMkxjUaDkpKa/QfE4IaI6Maj00nILRaBklyFVgdHB5XVwEmnk/DHP1cR4KFB/2q20jiRnIuJX+2Fi7Mj3hjbEbd1FbVOP+29jFdXnQAAbHxuIErKdfjzZIphCs7JQYU3xnbEL/uTEOSlgSSJ5f+dWnjh0y3nAQA+bs7Y9/JQnLyahyOJOejXxh/tgj3R6z8bkV3ZpDLMxxXJOcW4s0cYJAlQOzrg5dEd8OyvR7BNVpBeEy393JCYZTv7VJ0eLX2w4qn+13UNc7X5/lZ8sf2vv/6KmTNnYuHChejTpw8++ugjjBw5EvHx8QgKCrL6HC8vL8THG9N5jWlOkIiIGh8HB5VFYAPA6kar8ueM6xZWo+t3DvPG0ddHwEFl+p30QN9WiApwR1ZhGdoGewIAuoR7IzW3FMsPX8FTg9vgwbhIPBgXaXHNCD83zNsQj5dHd4DGyRE9WvqiR0tfw+NfPNgLk77dh8lxkZg1MgbJ2cWINFsB9va4znj0h4Po0coXzg4qLN6fiHKtyGlEBbhj9qj2WHU0GfklFXB2dMCV7CK8NKo9jiTmYMXhZHRq4YUtZ9JRoZPg7KjC/+7qipm/Hascnyv+d2dXPPDNPugkMY3WPcIXkQFu9bp3W00onrnp06cPevfujc8++wwAoNPpEBERgaeffhovvfSSxfmLFi3CjBkzkJOTU6fXY+aGiIiUVq7VYXt8Bga0DTDUJdVFhVZnM0Azdy4tHwcuZeOO7mGGOpvqXL5WiI2n0hAT4omb2wbir5OpmPPHKfznjs4YEhOEP0+kIiGzEA/0bQlPl5otx6+LJpO5KSsrw6FDhzB79mzDMQcHBwwbNgx79uyp8nkFBQVo1aoVdDodevTogXfeeQedOnVqiCETERFdN2dHBwyz0e25pmoT2ABA22BPQwapplr5u2Pqza0N90d2CsHITiGG+7d2DrH2NEXV7lOxs8zMTGi1WgQHm/4BBwcHIzXVesfNmJgYfPvtt1i9ejV++ukn6HQ69OvXD1euXLF6fmlpKfLy8kx+iIiIqPlSNLipi7i4OEyaNAndunXDoEGDsGLFCgQGBuKLL76wev7cuXPh7e1t+ImIiGjgERMREVFDUjS4CQgIgKOjI9LSTLtOpqWlISSkZmkuZ2dndO/eHefPn7f6+OzZs5Gbm2v4SUpKuu5xExERUeOlaHCjVqvRs2dPbN682XBMp9Nh8+bNiIuLq9E1tFotjh8/jtDQUKuPazQaeHl5mfwQERFR86X4UvCZM2di8uTJ6NWrF2666SZ89NFHKCwsNPSymTRpEsLCwjB37lwAwJw5c9C3b19ER0cjJycH77//Pi5fvoypU6cq+TaIiIiokVA8uJkwYQIyMjLw+uuvIzU1Fd26dcOff/5pKDJOTEyEg4MxwZSdnY1HH30Uqamp8PX1Rc+ePfH333+jY8eOSr0FIiIiakQU73PT0NjnhoiIqOmpzfd3k1stRURERGQLgxsiIiJqVhjcEBERUbPC4IaIiIiaFQY3RERE1KwwuCEiIqJmhcENERERNSuKN/FraPq2PtwdnIiIqOnQf2/XpD3fDRfc5OfnAwB3ByciImqC8vPz4e3tbfOcG65DsU6nw9WrV+Hp6QmVSmXXa+fl5SEiIgJJSUnsflyP+Dk3HH7WDYOfc8Pg59xw6uOzliQJ+fn5aNGihcm2TNbccJkbBwcHhIeH1+trcPfxhsHPueHws24Y/JwbBj/nhmPvz7q6jI0eC4qJiIioWWFwQ0RERM0Kgxs70mg0eOONN6DRaJQeSrPGz7nh8LNuGPycGwY/54aj9Gd9wxUUExERUfPGzA0RERE1KwxuiIiIqFlhcENERETNCoMbIiIialYY3NjJ/PnzERkZCRcXF/Tp0wf79+9XekhNzo4dOzB27Fi0aNECKpUKq1atMnlckiS8/vrrCA0NhaurK4YNG4Zz586ZnJOVlYX7778fXl5e8PHxwSOPPIKCgoIGfBeN29y5c9G7d294enoiKCgI48ePR3x8vMk5JSUlmDZtGvz9/eHh4YG77roLaWlpJuckJiZizJgxcHNzQ1BQEF544QVUVFQ05Ftp9BYsWICuXbsampjFxcVh/fr1hsf5OdePd999FyqVCjNmzDAc42dtH2+++SZUKpXJT/v27Q2PN6rPWaLrtmTJEkmtVkvffvutdPLkSenRRx+VfHx8pLS0NKWH1qSsW7dOeuWVV6QVK1ZIAKSVK1eaPP7uu+9K3t7e0qpVq6Rjx45Jt99+uxQVFSUVFxcbzrn11lul2NhYae/evdLOnTul6OhoaeLEiQ38ThqvkSNHSt9995104sQJ6ejRo9Lo0aOlli1bSgUFBYZznnjiCSkiIkLavHmzdPDgQalv375Sv379DI9XVFRInTt3loYNGyYdOXJEWrdunRQQECDNnj1bibfUaP3+++/S2rVrpbNnz0rx8fHSyy+/LDk7O0snTpyQJImfc33Yv3+/FBkZKXXt2lV69tlnDcf5WdvHG2+8IXXq1ElKSUkx/GRkZBgeb0yfM4MbO7jpppukadOmGe5rtVqpRYsW0ty5cxUcVdNmHtzodDopJCREev/99w3HcnJyJI1GI/3yyy+SJEnSqVOnJADSgQMHDOesX79eUqlUUnJycoONvSlJT0+XAEjbt2+XJEl8ps7OztLSpUsN55w+fVoCIO3Zs0eSJBGEOjg4SKmpqYZzFixYIHl5eUmlpaUN+waaGF9fX+nrr7/m51wP8vPzpbZt20obN26UBg0aZAhu+FnbzxtvvCHFxsZafayxfc6clrpOZWVlOHToEIYNG2Y45uDggGHDhmHPnj0Kjqx5SUhIQGpqqsnn7O3tjT59+hg+5z179sDHxwe9evUynDNs2DA4ODhg3759DT7mpiA3NxcA4OfnBwA4dOgQysvLTT7n9u3bo2XLliafc5cuXRAcHGw4Z+TIkcjLy8PJkycbcPRNh1arxZIlS1BYWIi4uDh+zvVg2rRpGDNmjMlnCvC/aXs7d+4cWrRogdatW+P+++9HYmIigMb3Od9wG2faW2ZmJrRarckfFgAEBwfjzJkzCo2q+UlNTQUAq5+z/rHU1FQEBQWZPO7k5AQ/Pz/DOWSk0+kwY8YM9O/fH507dwYgPkO1Wg0fHx+Tc80/Z2t/DvrHyOj48eOIi4tDSUkJPDw8sHLlSnTs2BFHjx7l52xHS5YsweHDh3HgwAGLx/jftP306dMHixYtQkxMDFJSUvDWW2/h5ptvxokTJxrd58zghugGNW3aNJw4cQK7du1SeijNVkxMDI4ePYrc3FwsW7YMkydPxvbt25UeVrOSlJSEZ599Fhs3boSLi4vSw2nWRo0aZbjdtWtX9OnTB61atcJvv/0GV1dXBUdmidNS1ykgIACOjo4WFeFpaWkICQlRaFTNj/6ztPU5h4SEID093eTxiooKZGVl8c/CzPTp07FmzRps3boV4eHhhuMhISEoKytDTk6Oyfnmn7O1Pwf9Y2SkVqsRHR2Nnj17Yu7cuYiNjcXHH3/Mz9mODh06hPT0dPTo0QNOTk5wcnLC9u3b8cknn8DJyQnBwcH8rOuJj48P2rVrh/Pnzze6/6YZ3FwntVqNnj17YvPmzYZjOp0OmzdvRlxcnIIja16ioqIQEhJi8jnn5eVh3759hs85Li4OOTk5OHTokOGcLVu2QKfToU+fPg0+5sZIkiRMnz4dK1euxJYtWxAVFWXyeM+ePeHs7GzyOcfHxyMxMdHkcz5+/LhJILlx40Z4eXmhY8eODfNGmiidTofS0lJ+znY0dOhQHD9+HEePHjX89OrVC/fff7/hNj/r+lFQUIALFy4gNDS08f03bdfy5BvUkiVLJI1GIy1atEg6deqU9Nhjj0k+Pj4mFeFUvfz8fOnIkSPSkSNHJADSBx98IB05ckS6fPmyJEliKbiPj4+0evVq6Z9//pHGjRtndSl49+7dpX379km7du2S2rZty6XgMk8++aTk7e0tbdu2zWQ5Z1FRkeGcJ554QmrZsqW0ZcsW6eDBg1JcXJwUFxdneFy/nHPEiBHS0aNHpT///FMKDAzkslkzL730krR9+3YpISFB+ueff6SXXnpJUqlU0oYNGyRJ4udcn+SrpSSJn7W9PP/889K2bdukhIQEaffu3dKwYcOkgIAAKT09XZKkxvU5M7ixk08//VRq2bKlpFarpZtuuknau3ev0kNqcrZu3SoBsPiZPHmyJEliOfhrr70mBQcHSxqNRho6dKgUHx9vco1r165JEydOlDw8PCQvLy/poYcekvLz8xV4N42Ttc8XgPTdd98ZzikuLpaeeuopydfXV3Jzc5PuuOMOKSUlxeQ6ly5dkkaNGiW5urpKAQEB0vPPPy+Vl5c38Ltp3B5++GGpVatWklqtlgIDA6WhQ4caAhtJ4udcn8yDG37W9jFhwgQpNDRUUqvVUlhYmDRhwgTp/Pnzhscb0+eskiRJsm8uiIiIiEg5rLkhIiKiZoXBDRERETUrDG6IiIioWWFwQ0RERM0KgxsiIiJqVhjcEBERUbPC4IaIiIiaFQY3RHTD27ZtG1QqlcW+OETUNDG4ISIiomaFwQ0RERE1KwxuiEhxOp0Oc+fORVRUFFxdXREbG4tly5YBME4ZrV27Fl27doWLiwv69u2LEydOmFxj+fLl6NSpEzQaDSIjIzFv3jyTx0tLS/Hvf/8bERER0Gg0iI6OxjfffGNyzqFDh9CrVy+4ubmhX79+iI+Pr983TkT1gsENESlu7ty5+OGHH7Bw4UKcPHkSzz33HB544AFs377dcM4LL7yAefPm4cCBAwgMDMTYsWNRXl4OQAQl9957L+677z4cP34cb775Jl577TUsWrTI8PxJkybhl19+wSeffILTp0/jiy++gIeHh8k4XnnlFcybNw8HDx6Ek5MTHn744QZ5/0RkX9w4k4gUVVpaCj8/P2zatAlxcXGG41OnTkVRUREee+wxDBkyBEuWLMGECRMAAFlZWQgPD8eiRYtw77334v7770dGRgY2bNhgeP6LL76ItWvX4uTJkzh79ixiYmKwceNGDBs2zGIM27Ztw5AhQ7Bp0yYMHToUALBu3TqMGTMGxcXFcHFxqedPgYjsiZkbIlLU+fPnUVRUhOHDh8PDw8Pw88MPP+DChQuG8+SBj5+fH2JiYnD69GkAwOnTp9G/f3+T6/bv3x/nzp2DVqvF0aNH4ejoiEGDBtkcS9euXQ23Q0NDAQDp6enX/R6JqGE5KT0AIrqxFRQUAADWrl2LsLAwk8c0Go1JgFNXrq6uNTrP2dnZcFulUgEQ9UBE1LQwc0NEiurYsSM0Gg0SExMRHR1t8hMREWE4b+/evYbb2dnZOHv2LDp06AAA6NChA3bv3m1y3d27d6Ndu3ZwdHREly5doNPpTGp4iKj5YuaGiBTl6emJWbNm4bnnnoNOp8OAAQOQm5uL3bt3w8vLC61atQIAzJkzB/7+/ggODsYrr7yCgIAAjB8/HgDw/PPPo3fv3nj77bcxYcIE7NmzB5999hk+//xzAEBkZCQmT56Mhx9+GJ988gliY2Nx+fJlpKen495771XqrRNRPWFwQ0SKe/vttxEYGIi5c+fi4sWL8PHxQY8ePfDyyy8bpoXeffddPPvsszh37hy6deuGP/74A2q1GgDQo0cP/Pbbb3j99dfx9ttvIzQ0FHPmzMGUKVMMr7FgwQK8/PLLeOqpp3Dt2jW0bNkSL7/8shJvl4jqGVdLEVGjpl/JlJ2dDR8fH6WHQ0RNAGtuiIiIqFlhcENERETNCqeliIiIqFlh5oaIiIiaFQY3RERE1KwwuCEiIqJmhcENERERNSsMboiIiKhZYXBDREREzQqDGyIiImpWGNwQERFRs8LghoiIiJqV/wdCyIuoMFZCVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20BhswKfVvDb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20BhswKfVvDb",
    "outputId": "4f595238-5997-4c57-c5d4-2b7db26b821c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 12ms/step - loss: 1.3639 - accuracy: 0.6103\n",
      "Restored model, accuracy: 61.03%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_cnn, y_test_e_cnn)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "-Bl8iWbTQRlY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Bl8iWbTQRlY",
    "outputId": "289d9754-c9be-4410-9ba1-823a44f7ddd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at ./models/CNNSequntial_Model_8cls_131feat_61Acc.h5 \n"
     ]
    }
   ],
   "source": [
    "model_name = 'CNNSequntial_Model_8cls_131feat_61Acc.h5'\n",
    "save_dir = './models'\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZjPHYy0saL8A",
   "metadata": {
    "id": "ZjPHYy0saL8A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ad8c5de8-86fb-4ded-9158-71f1f2c2958a",
    "sm5XouA3GcU7",
    "dc283451-e5be-41f4-9936-9cfc26c33c4b",
    "3b833185",
    "fb541dfd",
    "11eaa733-2935-4b1d-a787-5b6a7912a554"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
